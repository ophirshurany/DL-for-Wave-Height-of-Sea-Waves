{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T18:22:21.961340Z",
     "start_time": "2019-09-30T18:22:21.940559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T18:22:22.370742Z",
     "start_time": "2019-09-30T18:22:22.349964Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "# Various python imports\n",
    "import datetime\n",
    "import math\n",
    "import pickle\n",
    "import collections\n",
    "import os.path as osp\n",
    "import configparser\n",
    "import copy\n",
    "\n",
    "# ML imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "# Jupyter\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# My code\n",
    "import Process\n",
    "import Load\n",
    "import Eval\n",
    "import Models\n",
    "import Split\n",
    "import TestInstanceParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T10:31:27.397895Z",
     "start_time": "2019-06-29T10:31:27.382663Z"
    }
   },
   "outputs": [],
   "source": [
    "# configuration file\n",
    "CONF_FILE_NAME = \"run_conf.ini\"\n",
    "conf = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config['Path'] = {'DATA_BASE_DIR ': r'C:\\Users\\User\\לימודים\\תואר שני\\פרויקט גמר\\Shir\\Data',\n",
    "                  'OUTPUT_BASE_DIR ': r'C:\\Users\\User\\לימודים\\תואר שני\\פרויקט גמר\\Shir\\ML_Wave\\output',\n",
    "                     'ADCP ': 'ADCP_lev_Dec17Apr18.csv',\n",
    "                 'BUOY_DEMO': 'haifa_cameriJan17.csv',\n",
    "                 'BUOY' :'Buoy_Nov17_Mar18.csv',\n",
    "                  'MODEL_DEEP' : 'ww3_lev_Dec17_Apr18.csv',\n",
    "                  'MODEL_SHALLOW': 'ww3_shik_Dec17_Apr18.csv'}\n",
    "\n",
    "config['Pref'] = {'ADCP_PREF': 'a',\n",
    "                  'BUOY_PREF': 'b',\n",
    "                  'PHYS_DEEP_PREF': 'ma',\n",
    "                 'PHYS_SHALLOW_PREF': 'mb'}\n",
    "config['Run Params']={}\n",
    "with open(CONF_FILE_NAME, 'w') as configfile:\n",
    "    config.write(configfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Path', 'Pref', 'Run Params']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run_conf.ini']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.read(CONF_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T10:31:27.878609Z",
     "start_time": "2019-06-29T10:31:27.861171Z"
    }
   },
   "outputs": [],
   "source": [
    "# red file and load consts\n",
    "\n",
    "#OUTPUT_BASE_DIR = conf['Path']['OUTPUT_BASE_DIR']\n",
    "OUTPUT_BASE_DIR=r'C:\\Users\\User\\לימודים\\תואר שני\\פרויקט גמר\\Shir\\ML_Wave\\output'\n",
    "ADCP_PREF = conf['Pref']['ADCP_PREF']\n",
    "BUOY_PREF = conf['Pref']['BUOY_PREF']\n",
    "PHYS_DEEP_PREF = conf['Pref']['PHYS_DEEP_PREF']\n",
    "PHYS_SHALLOW_PREF = conf['Pref']['PHYS_SHALLOW_PREF']\n",
    "\n",
    "files_and_pref = [\\\n",
    "    [conf['Path']['ADCP'], conf['Pref']['ADCP_PREF']],\n",
    "    [conf['Path']['BUOY'], conf['Pref']['BUOY_PREF']],\n",
    "    [conf['Path']['MODEL_DEEP'], conf['Pref']['PHYS_DEEP_PREF']],\n",
    "    [conf['Path']['MODEL_SHALLOW'], conf['Pref']['PHYS_SHALLOW_PREF']]\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ADCP_lev_Dec17Apr18.csv', 'a'],\n",
       " ['Buoy_Nov17_Mar18.csv', 'b'],\n",
       " ['ww3_lev_Dec17_Apr18.csv', 'ma'],\n",
       " ['ww3_shik_Dec17_Apr18.csv', 'mb']]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_and_pref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T10:31:35.277696Z",
     "start_time": "2019-06-29T10:31:28.164418Z"
    }
   },
   "outputs": [],
   "source": [
    "#full_data = Load.load_all_data(files_and_pref, conf['Path']['DATA_BASE_DIR'])\n",
    "new_dir=r'C:\\Users\\User\\לימודים\\תואר שני\\פרויקט גמר\\Shir\\Data'\n",
    "full_data = Load.load_all_data(files_and_pref, new_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_hs</th>\n",
       "      <th>a_dir</th>\n",
       "      <th>a_Tm</th>\n",
       "      <th>b_hs</th>\n",
       "      <th>b_dir</th>\n",
       "      <th>b_Tm</th>\n",
       "      <th>ma_hs</th>\n",
       "      <th>ma_dir</th>\n",
       "      <th>ma_Tm</th>\n",
       "      <th>mb_hs</th>\n",
       "      <th>mb_dir</th>\n",
       "      <th>mb_Tm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-04 11:00:00</th>\n",
       "      <td>0.900</td>\n",
       "      <td>333.000</td>\n",
       "      <td>33.050</td>\n",
       "      <td>0.300</td>\n",
       "      <td>93.000</td>\n",
       "      <td>2.630</td>\n",
       "      <td>0.284</td>\n",
       "      <td>87.000</td>\n",
       "      <td>4.220</td>\n",
       "      <td>0.284</td>\n",
       "      <td>316.000</td>\n",
       "      <td>5.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-04 11:10:00</th>\n",
       "      <td>0.600</td>\n",
       "      <td>333.000</td>\n",
       "      <td>9.820</td>\n",
       "      <td>0.300</td>\n",
       "      <td>88.000</td>\n",
       "      <td>2.610</td>\n",
       "      <td>0.282</td>\n",
       "      <td>86.000</td>\n",
       "      <td>4.240</td>\n",
       "      <td>0.282</td>\n",
       "      <td>315.000</td>\n",
       "      <td>5.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-04 11:20:00</th>\n",
       "      <td>0.600</td>\n",
       "      <td>284.000</td>\n",
       "      <td>9.460</td>\n",
       "      <td>0.300</td>\n",
       "      <td>84.000</td>\n",
       "      <td>2.590</td>\n",
       "      <td>0.279</td>\n",
       "      <td>84.000</td>\n",
       "      <td>4.270</td>\n",
       "      <td>0.279</td>\n",
       "      <td>314.000</td>\n",
       "      <td>5.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-04 11:30:00</th>\n",
       "      <td>0.600</td>\n",
       "      <td>235.000</td>\n",
       "      <td>9.620</td>\n",
       "      <td>0.300</td>\n",
       "      <td>84.000</td>\n",
       "      <td>2.720</td>\n",
       "      <td>0.277</td>\n",
       "      <td>81.000</td>\n",
       "      <td>4.290</td>\n",
       "      <td>0.277</td>\n",
       "      <td>313.000</td>\n",
       "      <td>5.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-04 11:40:00</th>\n",
       "      <td>0.500</td>\n",
       "      <td>186.000</td>\n",
       "      <td>4.300</td>\n",
       "      <td>0.300</td>\n",
       "      <td>50.000</td>\n",
       "      <td>2.760</td>\n",
       "      <td>0.275</td>\n",
       "      <td>78.000</td>\n",
       "      <td>4.310</td>\n",
       "      <td>0.275</td>\n",
       "      <td>313.000</td>\n",
       "      <td>5.980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     a_hs   a_dir   a_Tm  b_hs  b_dir  b_Tm  ma_hs  ma_dir  \\\n",
       "Date                                                                         \n",
       "2017-12-04 11:00:00 0.900 333.000 33.050 0.300 93.000 2.630  0.284  87.000   \n",
       "2017-12-04 11:10:00 0.600 333.000  9.820 0.300 88.000 2.610  0.282  86.000   \n",
       "2017-12-04 11:20:00 0.600 284.000  9.460 0.300 84.000 2.590  0.279  84.000   \n",
       "2017-12-04 11:30:00 0.600 235.000  9.620 0.300 84.000 2.720  0.277  81.000   \n",
       "2017-12-04 11:40:00 0.500 186.000  4.300 0.300 50.000 2.760  0.275  78.000   \n",
       "\n",
       "                     ma_Tm  mb_hs  mb_dir  mb_Tm  \n",
       "Date                                              \n",
       "2017-12-04 11:00:00  4.220  0.284 316.000  5.730  \n",
       "2017-12-04 11:10:00  4.240  0.282 315.000  5.810  \n",
       "2017-12-04 11:20:00  4.270  0.279 314.000  5.870  \n",
       "2017-12-04 11:30:00  4.290  0.277 313.000  5.930  \n",
       "2017-12-04 11:40:00  4.310  0.275 313.000  5.980  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-29T10:31:35.295941Z",
     "start_time": "2019-06-29T10:31:35.278889Z"
    }
   },
   "outputs": [],
   "source": [
    "def downsample_data(data, ratio_for_downsample=2):\n",
    "    return data.iloc[range(0, data.shape[0], ratio_for_downsample)]\n",
    "\n",
    "def get_feature_and_target_data(data, target_col_name, is_target_in_features=True):\n",
    "    if type(data) == list:\n",
    "        target = [d[[target_col_name]] for d in data]\n",
    "        if not is_target_in_features:\n",
    "            data = [d.drop(target_col_name, axis=1) for d in data]\n",
    "    else:\n",
    "        target = data[[target_col_name]]\n",
    "        if not is_target_in_features:\n",
    "            data = data.drop(target_col_name, axis=1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils for running tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold running functions (run single fold, run kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T01:11:55.912064Z",
     "start_time": "2019-10-01T01:11:55.864522Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_single_fold_train_test(df, phys_target, run_params, pre, curr_fold_num):\n",
    "    fold_dict = {}\n",
    "    fold_dict[\"fold_num\"] = curr_fold_num\n",
    "    train, val, test, phys_val, phys_test = Split.kfold_split_train_test(df, curr_fold_num,\n",
    "                                                k=run_params.k, phys_target=phys_target)\n",
    "    pre.fit(*get_feature_and_target_data(\n",
    "        train, run_params.target_col, run_params.is_target_in_input))\n",
    "    fold_dict[\"preprocess\"] = pre\n",
    "    X_train, y_train, dates_y_train = pre.transform(\n",
    "        *get_feature_and_target_data(train, run_params.target_col, run_params.is_target_in_input))\n",
    "    X_val, y_val, dates_y_val = pre.transform(\n",
    "        *get_feature_and_target_data(val, run_params.target_col, run_params.is_target_in_input))\n",
    "    X_test, y_test, dates_y_test = pre.transform(\n",
    "        *get_feature_and_target_data(test, run_params.target_col, run_params.is_target_in_input))\n",
    "    input_dim = X_train.shape[2]\n",
    "    model_structure_args = {\"look_back\": run_params.train_steps, \"input_dimension\": input_dim,\n",
    "                           \"build_config_description\": run_params.desc_str + \"_f{}\".format(curr_fold_num)}\n",
    "    \n",
    "    fold_dict[\"train\"] = {}\n",
    "    fold_dict[\"val\"] = {}\n",
    "    fold_dict[\"test\"] = {}\n",
    "    \n",
    "    fold_dict[\"train\"][\"dates\"] = dates_y_train\n",
    "    fold_dict[\"val\"][\"dates\"] = dates_y_val\n",
    "    fold_dict[\"test\"][\"dates\"] = dates_y_test\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        curr_model = run_params.model_class(**model_structure_args)\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        # save trained model\n",
    "        curr_model = curr_model.fit(X_train, y_train, val_data=(X_val, y_val), **run_params.model_args)\n",
    "    \n",
    "    fold_dict[\"model\"] = curr_model\n",
    "    \n",
    "    fold_dict[\"test\"][\"pred\"] = pre.inverse_scale_target(fold_dict[\"model\"].predict(X_test))\n",
    "    fold_dict[\"test\"][\"true\"]  = pre.inverse_scale_target(y_test.reshape(-1, 1))\n",
    "    fold_dict[\"test\"][\"ww3\"]  = phys_test.iloc[run_params.train_steps + run_params.pred_forward:].values.reshape(-1,1)\n",
    "    \n",
    "    fold_dict[\"val\"][\"pred\"] = pre.inverse_scale_target(fold_dict[\"model\"].predict(X_val))\n",
    "    fold_dict[\"val\"][\"true\"] = pre.inverse_scale_target(y_val.reshape(-1, 1))\n",
    "    fold_dict[\"val\"][\"ww3\"] = phys_val.iloc[run_params.train_steps + run_params.pred_forward:].values.reshape(-1,1)\n",
    "    \n",
    "    fold_dict[\"train\"][\"pred\"] = pre.inverse_scale_target(fold_dict[\"model\"].predict(X_train))\n",
    "    fold_dict[\"train\"][\"true\"] = pre.inverse_scale_target(y_train.reshape(-1, 1))\n",
    "    \n",
    "    fold_dict[\"results_test\"] = Eval.eval_pred_phys_const(fold_dict[\"test\"], pre)\n",
    "    fold_dict[\"results_val\"] = Eval.eval_pred_phys_const(fold_dict[\"val\"] , pre)\n",
    "    # for train we don't look at ww3 model or const guess. interesting only to see if there's overfit\n",
    "    train_eval = Eval.eval_model(\n",
    "        fold_dict[\"train\"][\"true\"], fold_dict[\"train\"][\"pred\"])\n",
    "    fold_dict[\"results_train\"] = pd.Series(train_eval, name=\"ML\")\n",
    "    return fold_dict\n",
    "\n",
    "def run_kfold_train_test(df, phys_target, run_params, pre):\n",
    "    folds_run_data = {}\n",
    "    folds_run_data[\"run_params\"] = run_params\n",
    "    results_test = []\n",
    "    results_val = []\n",
    "    results_train = []\n",
    "    folds_to_run_on = list(range(run_params.k))\n",
    "    if run_params.num_folds_to_run:\n",
    "    # if num_folds_to_run < k, prefer running on last folds\n",
    "        folds_to_run_on = folds_to_run_on[-run_params.num_folds_to_run:]\n",
    "    folds_run_data[\"folds_dict\"] = {}\n",
    "    for i in folds_to_run_on:\n",
    "        print(\"##### Running on fold {} #####\".format(i))\n",
    "        curr_fold_results = run_single_fold_train_test(df, phys_target, run_params, pre, i)\n",
    "        folds_run_data[\"folds_dict\"][i] = curr_fold_results\n",
    "        results_test.append(folds_run_data[\"folds_dict\"][i][\"results_test\"].assign(fold=i))\n",
    "        results_val.append(folds_run_data[\"folds_dict\"][i][\"results_val\"].assign(fold=i))\n",
    "        results_train.append(folds_run_data[\"folds_dict\"][i][\"results_train\"].to_frame().assign(fold=i))\n",
    "    results_test = pd.concat(results_test)\n",
    "    results_val = pd.concat(results_val)\n",
    "    results_train = pd.concat(results_train)\n",
    "    results_test = results_test.set_index(['fold', results_test.index])\n",
    "    results_val = results_val.set_index(['fold', results_val.index])\n",
    "    results_train = results_train.set_index(['fold', results_train.index])\n",
    "    folds_run_data[\"results_test\"] = results_test\n",
    "    folds_run_data[\"results_val\"] = results_val\n",
    "    folds_run_data[\"results_train\"] = results_train\n",
    "    return folds_run_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Cell to rule them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T01:11:57.729290Z",
     "start_time": "2019-10-01T01:11:57.709906Z"
    }
   },
   "outputs": [],
   "source": [
    "def multi_func_run(data, *, target_col, col_names_and_offsets, input_data_str_repr,\n",
    "                  pred_forward_hrs=4, look_back_hrs=12, time_sample_res_minutes=10):\n",
    "    \"\"\"\n",
    "    receive \n",
    "    \"\"\"\n",
    "    model_str_repr = 'lstm1'\n",
    "#     pred_forward_hrs = 4\n",
    "#     look_back_hrs = 12\n",
    "#     time_sample_res_minutes= 10\n",
    "    k = 5\n",
    "    num_folds_to_run = 5\n",
    "\n",
    "    \n",
    "    model_train_args = {\"num_epochs\" : 16, \"batch_size\": 100}\n",
    "    model_class = Models.LSTMModel\n",
    "    # model_class = Models.FCNNModel\n",
    "    # model_class = Models.RandomForestModel\n",
    "    \n",
    "    col_names_and_offsets = col_names_and_offsets*int(60/time_sample_res_minutes)\n",
    "    \n",
    "    is_target_in_input=True\n",
    "    if target_col not in col_names_and_offsets.index:\n",
    "        is_target_in_input = False\n",
    "        col_names_and_offsets[target_col] = 0\n",
    "    \n",
    "    run_params = TestInstanceParams.TestInstanceParams(input_data_str_repr=input_data_str_repr, \\\n",
    "        model_str_repr=model_str_repr, target_col=target_col, \\\n",
    "        is_target_in_input=is_target_in_input, pred_forward_hrs=pred_forward_hrs, \\\n",
    "        look_back_hrs=look_back_hrs, time_sample_res_minutes=time_sample_res_minutes, \\\n",
    "        k=k, num_folds_to_run=num_folds_to_run, \\\n",
    "        model_class=model_class, model_args=model_train_args, \\\n",
    "        desc_str_addition ='')\n",
    "    \n",
    "    data = downsample_data(data, run_params.downsample_ratio)\n",
    "    df = Load.get_df_for_model(data, col_names_and_offsets)\n",
    "    phys_target = df[run_params.phys_col]\n",
    "\n",
    "    pre = Process.PreprocessData(steps_back=run_params.train_steps, \\\n",
    "                                 y_length=1, step_size=1, \\\n",
    "                              gap_forward=run_params.pred_forward)\n",
    "    \n",
    "    run_folds_dict = run_kfold_train_test(df, phys_target, run_params, pre)\n",
    "    \n",
    "    pd.options.display.float_format = '{:,.3f}'.format\n",
    "    print(run_params.desc_str)\n",
    "    display(run_folds_dict[\"results_test\"].groupby(level=1).mean()[['rmse', 'r2', 'si', 'mae', 'max_error', 'my_weighted_rmse']])\n",
    "    return run_folds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T01:11:58.350712Z",
     "start_time": "2019-10-01T01:11:58.333240Z"
    }
   },
   "outputs": [],
   "source": [
    "# run_config_dict_single_example = {'col_names_and_offsets': cols_offsets,\n",
    "#   'target_col': 'b_hs', 'input_data_str_repr':'mb4'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T01:11:58.809942Z",
     "start_time": "2019-10-01T01:11:58.787179Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#### BUILD RUN CONFIGS ####\n",
    "target_cols = ['b_hs', 'a_hs']\n",
    "\n",
    "zero_offset = [0,0,0,0]\n",
    "four_offset = [4,0,0,0]\n",
    "eight_offset = [8,0,0,0]\n",
    "offsets = [four_offset, zero_offset, eight_offset]\n",
    "\n",
    "# Build data configurations and strings:\n",
    "b_only_model = ('mb_hs',)\n",
    "b_model_local_measurement = ('mb_hs', 'b_hs')\n",
    "b_model_other_measurement = ('mb_hs', 'a_hs')\n",
    "b_model_both_measurement = ('mb_hs', 'b_hs', 'a_hs')\n",
    "\n",
    "str_b_only_model = 'mb'\n",
    "str_b_model_local_measurement = 'hbmb'\n",
    "str_b_model_other_measurement = 'hamb'\n",
    "str_b_model_both_measurement = 'hahbmb'\n",
    "\n",
    "data_options = [b_only_model, b_model_local_measurement,\n",
    "                b_model_other_measurement, b_model_both_measurement]\n",
    "strings = [str_b_only_model, str_b_model_local_measurement, str_b_model_other_measurement,\n",
    "           str_b_model_both_measurement]\n",
    "\n",
    "# creates tuples of - actual data columns, and the string representation for this data usage\n",
    "data2string = dict(zip(data_options, strings))\n",
    "\n",
    "\n",
    "# Build list of configuration dictionaries, which will later use multi_func_run in order\n",
    "# to run all configurations of: offests, target columns, and data combinations\n",
    "run_config_dicts_list = []\n",
    "for offset_size in offsets:\n",
    "    for target_col in target_cols:\n",
    "        for data_opt, string_rpr in zip(data_options, strings):\n",
    "            col_offsets = pd.Series(index=data_opt, data=offset_size[:len(data_opt)])\n",
    "            run_config_dicts_list.append({\"col_names_and_offsets\":col_offsets,\n",
    "                            \"target_col\": target_col, \\\n",
    "                                'input_data_str_repr':string_rpr + str(offset_size[0])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T01:11:59.448867Z",
     "start_time": "2019-10-01T01:11:59.428519Z"
    }
   },
   "outputs": [],
   "source": [
    "#### BUILD RUN CONFIGS ####\n",
    "# Using Data from one location (Buoy) for Forecasting conditions in another location (ADCP)\n",
    "target_cols = ['a_hs']\n",
    "\n",
    "zero_offset = [0,0,0,0]\n",
    "four_offset = [4,0,0,0]\n",
    "eight_offset = [8,0,0,0]\n",
    "offsets = [zero_offset, four_offset, eight_offset]\n",
    "\n",
    "# Build data configurations and strings:\n",
    "a_only_model = ('ma_hs',)\n",
    "a_model_other_hs = ('ma_hs', 'b_hs')\n",
    "a_model_other_all = ('ma_hs', 'b_hs', 'b_dir')\n",
    "other_all = ('b_hs', 'b_dir')\n",
    "\n",
    "str_a_only_model = 'ma'\n",
    "str_a_model_other_hs = 'hbma'\n",
    "str_model_other_all = 'folddirhbma'\n",
    "str_other_all = 'folddirhb'\n",
    "\n",
    "data_options = [a_only_model, a_model_other_hs,\n",
    "                a_model_other_all, other_all]\n",
    "strings = [str_a_only_model, str_a_model_other_hs, str_model_other_all,\n",
    "           str_other_all]\n",
    "# creates tuples of - actual data columns, and the string representation for this data usage\n",
    "data2string = dict(zip(data_options, strings))\n",
    "\n",
    "\n",
    "# Build list of configuration dictionaries, which will later use multi_func_run in order\n",
    "# to run all configurations of: offests, target columns, and data combinations\n",
    "run_config_dicts_list = []\n",
    "for offset_size in offsets:\n",
    "    for target_col in target_cols:\n",
    "        for data_opt, string_rpr in zip(data_options, strings):\n",
    "            col_offsets = pd.Series(index=data_opt, data=offset_size[:len(data_opt)])\n",
    "            run_config_dicts_list.append({\"col_names_and_offsets\":col_offsets,\n",
    "                            \"target_col\": target_col, \\\n",
    "                                'input_data_str_repr':string_rpr + str(offset_size[0])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T23:13:52.653582Z",
     "start_time": "2019-10-03T23:13:52.634611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'col_names_and_offsets': ma_hs    0\n",
       "  dtype: int64,\n",
       "  'target_col': 'a_hs',\n",
       "  'input_data_str_repr': 'ma0'},\n",
       " {'col_names_and_offsets': ma_hs    0\n",
       "  b_hs     0\n",
       "  dtype: int64,\n",
       "  'target_col': 'a_hs',\n",
       "  'input_data_str_repr': 'hbma0'},\n",
       " {'col_names_and_offsets': ma_hs    0\n",
       "  b_hs     0\n",
       "  b_dir    0\n",
       "  dtype: int64,\n",
       "  'target_col': 'a_hs',\n",
       "  'input_data_str_repr': 'folddirhbma0'},\n",
       " {'col_names_and_offsets': b_hs     0\n",
       "  b_dir    0\n",
       "  dtype: int64,\n",
       "  'target_col': 'a_hs',\n",
       "  'input_data_str_repr': 'folddirhb0'},\n",
       " {'col_names_and_offsets': ma_hs    4\n",
       "  dtype: int64,\n",
       "  'target_col': 'a_hs',\n",
       "  'input_data_str_repr': 'ma4'},\n",
       " {'col_names_and_offsets': ma_hs    4\n",
       "  b_hs     0\n",
       "  dtype: int64,\n",
       "  'target_col': 'a_hs',\n",
       "  'input_data_str_repr': 'hbma4'},\n",
       " {'col_names_and_offsets': ma_hs    4\n",
       "  b_hs     0\n",
       "  b_dir    0\n",
       "  dtype: int64,\n",
       "  'target_col': 'a_hs',\n",
       "  'input_data_str_repr': 'folddirhbma4'},\n",
       " {'col_names_and_offsets': b_hs     4\n",
       "  b_dir    0\n",
       "  dtype: int64,\n",
       "  'target_col': 'a_hs',\n",
       "  'input_data_str_repr': 'folddirhb4'},\n",
       " {'col_names_and_offsets': ma_hs    8\n",
       "  dtype: int64,\n",
       "  'target_col': 'a_hs',\n",
       "  'input_data_str_repr': 'ma8'},\n",
       " {'col_names_and_offsets': ma_hs    8\n",
       "  b_hs     0\n",
       "  dtype: int64,\n",
       "  'target_col': 'a_hs',\n",
       "  'input_data_str_repr': 'hbma8'},\n",
       " {'col_names_and_offsets': ma_hs    8\n",
       "  b_hs     0\n",
       "  b_dir    0\n",
       "  dtype: int64,\n",
       "  'target_col': 'a_hs',\n",
       "  'input_data_str_repr': 'folddirhbma8'},\n",
       " {'col_names_and_offsets': b_hs     8\n",
       "  b_dir    0\n",
       "  dtype: int64,\n",
       "  'target_col': 'a_hs',\n",
       "  'input_data_str_repr': 'folddirhb8'}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_config_dicts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T21:51:24.295970Z",
     "start_time": "2019-10-04T08:50:59.157106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "           RUN NUMBER 1\n",
      "--------------------------------------\n",
      "##### Running on fold 0 #####\n",
      "Train on 13090 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00122, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 35s - loss: 0.0165 - val_loss: 0.0012\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00122\n",
      "13090/13090 - 31s - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00122\n",
      "13090/13090 - 32s - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00122 to 0.00105, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 34s - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00105\n",
      "13090/13090 - 33s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00105 to 0.00105, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 33s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00105 to 0.00101, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 33s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00101\n",
      "13090/13090 - 33s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00101\n",
      "13090/13090 - 32s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00101\n",
      "13090/13090 - 31s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 00010: early stopping\n",
      "##### Running on fold 1 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00304, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 37s - loss: 0.0099 - val_loss: 0.0030\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00304 to 0.00128, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 33s - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00128\n",
      "12994/12994 - 34s - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00128\n",
      "12994/12994 - 34s - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00128 to 0.00124, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 34s - loss: 9.6133e-04 - val_loss: 0.0012\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00124 to 0.00119, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 35s - loss: 9.5272e-04 - val_loss: 0.0012\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00119 to 0.00117, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 37s - loss: 9.2650e-04 - val_loss: 0.0012\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00117 to 0.00116, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 37s - loss: 9.1503e-04 - val_loss: 0.0012\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00116 to 0.00115, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 36s - loss: 9.0082e-04 - val_loss: 0.0011\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00115\n",
      "12994/12994 - 36s - loss: 9.2127e-04 - val_loss: 0.0012\n",
      "Epoch 11/16\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00115\n",
      "12994/12994 - 36s - loss: 8.7492e-04 - val_loss: 0.0012\n",
      "Epoch 12/16\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00115\n",
      "12994/12994 - 36s - loss: 8.6656e-04 - val_loss: 0.0012\n",
      "Epoch 00012: early stopping\n",
      "##### Running on fold 2 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00270, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 44s - loss: 0.0162 - val_loss: 0.0027\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00270\n",
      "12994/12994 - 37s - loss: 0.0015 - val_loss: 59143127733.2586\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00270 to 0.00178, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 36s - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00178\n",
      "12994/12994 - 37s - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00178\n",
      "12994/12994 - 37s - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00178 to 0.00169, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 37s - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00169 to 0.00164, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 37s - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00164 to 0.00157, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 37s - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00157\n",
      "12994/12994 - 37s - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00157\n",
      "12994/12994 - 37s - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 11/16\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00157\n",
      "12994/12994 - 39s - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 00011: early stopping\n",
      "##### Running on fold 3 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00082, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 48s - loss: 0.0178 - val_loss: 8.2011e-04\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00082 to 0.00078, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 39s - loss: 0.0015 - val_loss: 7.7743e-04\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00078 to 0.00078, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 40s - loss: 0.0014 - val_loss: 7.7643e-04\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00078 to 0.00075, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 39s - loss: 0.0016 - val_loss: 7.5090e-04\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00075 to 0.00069, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 39s - loss: 0.0014 - val_loss: 6.9078e-04\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00069\n",
      "12994/12994 - 39s - loss: 0.0013 - val_loss: 7.4871e-04\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00069\n",
      "12994/12994 - 39s - loss: 0.0013 - val_loss: 8.2953e-04\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00069\n",
      "12994/12994 - 39s - loss: 0.0012 - val_loss: 8.1175e-04\n",
      "Epoch 00008: early stopping\n",
      "##### Running on fold 4 #####\n",
      "Train on 13088 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00064, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 49s - loss: 0.0172 - val_loss: 6.4103e-04\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00064 to 0.00052, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 43s - loss: 0.0017 - val_loss: 5.1947e-04\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00052\n",
      "13088/13088 - 44s - loss: 0.0015 - val_loss: 8.0837e-04\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00052\n",
      "13088/13088 - 43s - loss: 0.0017 - val_loss: 6.2370e-04\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00052\n",
      "13088/13088 - 43s - loss: 0.0015 - val_loss: 6.0405e-04\n",
      "Epoch 00005: early stopping\n",
      "a4h_10mma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.215</td>\n",
       "      <td>0.649</td>\n",
       "      <td>27.949</td>\n",
       "      <td>0.158</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.215 0.649 27.949 0.158      1.004             0.258\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "           RUN NUMBER 2\n",
      "--------------------------------------\n",
      "##### Running on fold 0 #####\n",
      "Train on 13090 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00124, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 51s - loss: 0.0090 - val_loss: 0.0012\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00124\n",
      "13090/13090 - 42s - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00124\n",
      "13090/13090 - 42s - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00124 to 0.00123, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 42s - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00123 to 0.00114, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 45s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00114\n",
      "13090/13090 - 46s - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00114 to 0.00110, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 49s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00110\n",
      "13090/13090 - 47s - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00110 to 0.00108, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 48s - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00108 to 0.00106, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 47s - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 11/16\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00106 to 0.00102, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 48s - loss: 9.6845e-04 - val_loss: 0.0010\n",
      "Epoch 12/16\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00102\n",
      "13090/13090 - 48s - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 13/16\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00102 to 0.00101, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 47s - loss: 9.2932e-04 - val_loss: 0.0010\n",
      "Epoch 14/16\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00101\n",
      "13090/13090 - 46s - loss: 9.4001e-04 - val_loss: 0.0010\n",
      "Epoch 15/16\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00101 to 0.00100, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 48s - loss: 9.1021e-04 - val_loss: 0.0010\n",
      "Epoch 16/16\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00100\n",
      "13090/13090 - 48s - loss: 9.3917e-04 - val_loss: 0.0010\n",
      "##### Running on fold 1 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00361, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 64s - loss: 0.0205 - val_loss: 0.0036\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00361 to 0.00216, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 50s - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00216 to 0.00209, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 53s - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00209 to 0.00193, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 53s - loss: 9.8169e-04 - val_loss: 0.0019\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00193\n",
      "12994/12994 - 52s - loss: 9.5407e-04 - val_loss: 0.0019\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00193 to 0.00186, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 51s - loss: 9.3237e-04 - val_loss: 0.0019\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00186 to 0.00180, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 54s - loss: 9.3445e-04 - val_loss: 0.0018\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00180\n",
      "12994/12994 - 52s - loss: 9.0907e-04 - val_loss: 0.0018\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00180 to 0.00176, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 50s - loss: 9.0765e-04 - val_loss: 0.0018\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00176\n",
      "12994/12994 - 51s - loss: 9.1225e-04 - val_loss: 0.0019\n",
      "Epoch 11/16\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00176 to 0.00171, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 49s - loss: 8.8786e-04 - val_loss: 0.0017\n",
      "Epoch 12/16\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00171\n",
      "12994/12994 - 51s - loss: 8.9654e-04 - val_loss: 0.0019\n",
      "Epoch 13/16\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00171 to 0.00164, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 52s - loss: 8.7988e-04 - val_loss: 0.0016\n",
      "Epoch 14/16\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00164\n",
      "12994/12994 - 50s - loss: 8.6672e-04 - val_loss: 0.0020\n",
      "Epoch 15/16\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00164\n",
      "12994/12994 - 50s - loss: 30389.4883 - val_loss: 0.0027\n",
      "Epoch 16/16\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00164\n",
      "12994/12994 - 51s - loss: 7.9534e-04 - val_loss: 0.0017\n",
      "Epoch 00016: early stopping\n",
      "##### Running on fold 2 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00222, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 65s - loss: 0.0095 - val_loss: 0.0022\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00222\n",
      "12994/12994 - 52s - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00222\n",
      "12994/12994 - 50s - loss: 0.0015 - val_loss: 1312.2346\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00222 to 0.00150, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 52s - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00150\n",
      "12994/12994 - 53s - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00150\n",
      "12994/12994 - 51s - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00150 to 0.00143, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 52s - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00143\n",
      "12994/12994 - 50s - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00143\n",
      "12994/12994 - 52s - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00143\n",
      "12994/12994 - 52s - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 00010: early stopping\n",
      "##### Running on fold 3 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00104, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 63s - loss: 0.0091 - val_loss: 0.0010\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00104 to 0.00099, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 55s - loss: 0.0012 - val_loss: 9.9112e-04\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00099\n",
      "12994/12994 - 55s - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00099 to 0.00098, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 54s - loss: 0.0012 - val_loss: 9.7606e-04\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00098 to 0.00095, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 54s - loss: 0.0012 - val_loss: 9.5192e-04\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00095\n",
      "12994/12994 - 53s - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00095\n",
      "12994/12994 - 54s - loss: 0.0011 - val_loss: 9.8898e-04\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00095\n",
      "12994/12994 - 52s - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 00008: early stopping\n",
      "##### Running on fold 4 #####\n",
      "Train on 13088 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00043, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 69s - loss: 0.0128 - val_loss: 4.2972e-04\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00043\n",
      "13088/13088 - 54s - loss: 0.0014 - val_loss: 5.2304e-04\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00043\n",
      "13088/13088 - 53s - loss: 0.0015 - val_loss: 4.4693e-04\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00043\n",
      "13088/13088 - 53s - loss: 0.0015 - val_loss: 4.4562e-04\n",
      "Epoch 00004: early stopping\n",
      "a4h_10mhbma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.212</td>\n",
       "      <td>0.690</td>\n",
       "      <td>26.758</td>\n",
       "      <td>0.153</td>\n",
       "      <td>1.005</td>\n",
       "      <td>0.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.212 0.690 26.758 0.153      1.005             0.251\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "           RUN NUMBER 3\n",
      "--------------------------------------\n",
      "##### Running on fold 0 #####\n",
      "Train on 13090 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00128, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 73s - loss: 0.0122 - val_loss: 0.0013\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00128 to 0.00125, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 62s - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00125\n",
      "13090/13090 - 62s - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00125 to 0.00115, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 63s - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00115 to 0.00112, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 61s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00112 to 0.00110, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 64s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00110 to 0.00108, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 63s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00108 to 0.00107, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 63s - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00107\n",
      "13090/13090 - 61s - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00107 to 0.00106, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 61s - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 11/16\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00106\n",
      "13090/13090 - 67s - loss: 9.8127e-04 - val_loss: 0.0011\n",
      "Epoch 12/16\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00106 to 0.00103, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 65s - loss: 9.7463e-04 - val_loss: 0.0010\n",
      "Epoch 13/16\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00103\n",
      "13090/13090 - 63s - loss: 9.5477e-04 - val_loss: 0.0010\n",
      "Epoch 14/16\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00103 to 0.00101, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 61s - loss: 9.6948e-04 - val_loss: 0.0010\n",
      "Epoch 15/16\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00101\n",
      "13090/13090 - 63s - loss: 9.4755e-04 - val_loss: 0.0010\n",
      "Epoch 16/16\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00101 to 0.00098, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 63s - loss: 0.0011 - val_loss: 9.8086e-04\n",
      "##### Running on fold 1 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00241, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 79s - loss: 0.0065 - val_loss: 0.0024\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00241 to 0.00175, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 63s - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00175 to 0.00157, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 66s - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00157 to 0.00151, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 67s - loss: 9.8812e-04 - val_loss: 0.0015\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00151 to 0.00146, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 67s - loss: 9.6354e-04 - val_loss: 0.0015\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00146\n",
      "12994/12994 - 66s - loss: 9.3725e-04 - val_loss: 0.0015\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00146 to 0.00144, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 65s - loss: 9.3402e-04 - val_loss: 0.0014\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00144\n",
      "12994/12994 - 61s - loss: 9.2640e-04 - val_loss: 0.0014\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00144 to 0.00142, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 66s - loss: 9.2500e-04 - val_loss: 0.0014\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00142\n",
      "12994/12994 - 66s - loss: 8.8788e-04 - val_loss: 0.0014\n",
      "Epoch 11/16\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00142 to 0.00142, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 67s - loss: 8.9924e-04 - val_loss: 0.0014\n",
      "Epoch 12/16\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00142 to 0.00142, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 66s - loss: 8.8411e-04 - val_loss: 0.0014\n",
      "Epoch 13/16\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00142 to 0.00141, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 66s - loss: 8.6028e-04 - val_loss: 0.0014\n",
      "Epoch 14/16\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00141\n",
      "12994/12994 - 68s - loss: 8.5548e-04 - val_loss: 0.0014\n",
      "Epoch 15/16\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00141\n",
      "12994/12994 - 68s - loss: 8.6097e-04 - val_loss: 0.0014\n",
      "Epoch 16/16\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00141\n",
      "12994/12994 - 60s - loss: 8.3301e-04 - val_loss: 0.0014\n",
      "Epoch 00016: early stopping\n",
      "##### Running on fold 2 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00211, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 80s - loss: 0.0132 - val_loss: 0.0021\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00211 to 0.00200, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 62s - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00200 to 0.00153, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 61s - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00153\n",
      "12994/12994 - 62s - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00153\n",
      "12994/12994 - 63s - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00153 to 0.00146, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 61s - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00146 to 0.00143, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 62s - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00143\n",
      "12994/12994 - 60s - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00143\n",
      "12994/12994 - 63s - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00143 to 0.00139, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 58s - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/16\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00139\n",
      "12994/12994 - 61s - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 12/16\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00139\n",
      "12994/12994 - 58s - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 13/16\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00139 to 0.00139, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 62s - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 14/16\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00139 to 0.00137, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 58s - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 15/16\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00137\n",
      "12994/12994 - 62s - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 16/16\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00137 to 0.00137, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 63s - loss: 0.0012 - val_loss: 0.0014\n",
      "##### Running on fold 3 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00103, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 80s - loss: 0.0086 - val_loss: 0.0010\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00103 to 0.00093, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 70s - loss: 0.0015 - val_loss: 9.3441e-04\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00093 to 0.00091, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 66s - loss: 0.0014 - val_loss: 9.0729e-04\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00091\n",
      "12994/12994 - 69s - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00091\n",
      "12994/12994 - 68s - loss: 0.0016 - val_loss: 9.7524e-04\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00091\n",
      "12994/12994 - 66s - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 00006: early stopping\n",
      "##### Running on fold 4 #####\n",
      "Train on 13088 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00041, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 87s - loss: 0.0114 - val_loss: 4.0569e-04\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00041\n",
      "13088/13088 - 67s - loss: 0.0014 - val_loss: 5.2781e-04\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00041\n",
      "13088/13088 - 65s - loss: 0.0014 - val_loss: 4.8967e-04\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00041\n",
      "13088/13088 - 67s - loss: 0.0016 - val_loss: 4.7770e-04\n",
      "Epoch 00004: early stopping\n",
      "a4h_10mfolddirhbma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.199</td>\n",
       "      <td>0.806</td>\n",
       "      <td>26.838</td>\n",
       "      <td>0.138</td>\n",
       "      <td>1.003</td>\n",
       "      <td>0.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.199 0.806 26.838 0.138      1.003             0.231\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "           RUN NUMBER 4\n",
      "--------------------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ma_hs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ma_hs'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-23dde9ece3b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"           RUN NUMBER {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--------------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mfolds_run_results_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmulti_func_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mfolds_run_results_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"run_config\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mrun_description_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfolds_run_results_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"run_params\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesc_str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-ea9baebb5740>\u001b[0m in \u001b[0;36mmulti_func_run\u001b[1;34m(data, target_col, col_names_and_offsets, input_data_str_repr, pred_forward_hrs, look_back_hrs, time_sample_res_minutes)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdownsample_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownsample_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLoad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_df_for_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_names_and_offsets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mphys_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrun_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphys_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     pre = Process.PreprocessData(steps_back=run_params.train_steps, \\\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ma_hs'"
     ]
    }
   ],
   "source": [
    "all_results_dicts = collections.OrderedDict()\n",
    "for i, all_args in enumerate(run_config_dicts_list):\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"           RUN NUMBER {}\".format(i+1))\n",
    "    print(\"--------------------------------------\")\n",
    "    folds_run_results_dict = multi_func_run(full_data, **all_args);\n",
    "    folds_run_results_dict[\"run_config\"] = all_args\n",
    "    run_description_str = folds_run_results_dict[\"run_params\"].desc_str\n",
    "    save_directory = osp.join(OUTPUT_BASE_DIR, \"pickle\", \"model_forward_scen_1\")\n",
    "    # tensorflow is not letting model be saved in dictionary with pickle\n",
    "    # so this is a workaround\n",
    "    for fold_data in folds_run_results_dict[\"folds_dict\"].values():\n",
    "        saved_model_file_name = run_description_str + \"_model_fold_{}.h5\".format(\n",
    "                                fold_data['fold_num'])\n",
    "        fold_data['model'].save(osp.join(save_directory, \"models\",\n",
    "                            saved_model_file_name))\n",
    "        del fold_data['model']\n",
    "        fold_data['model_filename'] = saved_model_file_name\n",
    "    with open(osp.join(save_directory, run_description_str + \".pkl\"), \"wb\") as f:\n",
    "        pickle.dump(folds_run_results_dict, f)\n",
    "    all_results_dicts[run_description_str] = folds_run_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\לימודים\\\\תואר שני\\\\פרויקט גמר\\\\Shir\\\\ML_Wave\\\\output'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_results_dict = copy.copy(all_results_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-04T21:51:24.312986Z",
     "start_time": "2019-10-04T21:51:24.297265Z"
    }
   },
   "outputs": [],
   "source": [
    "first_run_results = copy.copy(all_results_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T19:02:22.902397Z",
     "start_time": "2019-10-04T21:51:24.314326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "           RUN NUMBER 1\n",
      "--------------------------------------\n",
      "##### Running on fold 0 #####\n",
      "Train on 13090 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00126, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 64s - loss: 0.0145 - val_loss: 0.0013\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00126\n",
      "13090/13090 - 56s - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00126 to 0.00118, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 63s - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00118 to 0.00114, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 69s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00114 to 0.00111, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 64s - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00111 to 0.00106, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 59s - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00106 to 0.00105, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 57s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00105 to 0.00104, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 56s - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00104\n",
      "13090/13090 - 56s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00104 to 0.00101, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 56s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 11/16\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00101\n",
      "13090/13090 - 56s - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 12/16\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00101\n",
      "13090/13090 - 60s - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 13/16\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00101\n",
      "13090/13090 - 72s - loss: 9.9750e-04 - val_loss: 0.0010\n",
      "Epoch 00013: early stopping\n",
      "##### Running on fold 1 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00384, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 74s - loss: 0.0120 - val_loss: 0.0038\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00384 to 0.00173, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 58s - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00173 to 0.00125, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 58s - loss: 9.8398e-04 - val_loss: 0.0012\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00125\n",
      "12994/12994 - 57s - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00125\n",
      "12994/12994 - 57s - loss: 9.6844e-04 - val_loss: 0.0013\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00125\n",
      "12994/12994 - 61s - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 00006: early stopping\n",
      "##### Running on fold 2 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00271, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 68s - loss: 0.0131 - val_loss: 0.0027\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00271\n",
      "12994/12994 - 63s - loss: 0.0015 - val_loss: 3328874.3975\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00271\n",
      "12994/12994 - 62s - loss: 0.0017 - val_loss: 0.0622\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00271 to 0.00192, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 62s - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00192 to 0.00143, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 67s - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00143\n",
      "12994/12994 - 109s - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00143\n",
      "12994/12994 - 83s - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00143\n",
      "12994/12994 - 69s - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 00008: early stopping\n",
      "##### Running on fold 3 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00092, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 112s - loss: 0.0139 - val_loss: 9.2409e-04\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00092 to 0.00088, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 99s - loss: 0.0021 - val_loss: 8.7645e-04\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00088 to 0.00074, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 82s - loss: 0.0016 - val_loss: 7.3796e-04\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00074\n",
      "12994/12994 - 80s - loss: 0.0014 - val_loss: 7.5205e-04\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00074\n",
      "12994/12994 - 82s - loss: 0.0016 - val_loss: 8.2614e-04\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00074\n",
      "12994/12994 - 78s - loss: 0.0013 - val_loss: 7.5075e-04\n",
      "Epoch 00006: early stopping\n",
      "##### Running on fold 4 #####\n",
      "Train on 13088 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00036, saving model to output\\models\\a4h_10mma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 108s - loss: 0.0138 - val_loss: 3.5665e-04\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00036\n",
      "13088/13088 - 85s - loss: 0.0016 - val_loss: 3.8863e-04\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00036\n",
      "13088/13088 - 79s - loss: 0.0014 - val_loss: 4.8137e-04\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00036\n",
      "13088/13088 - 79s - loss: 0.0015 - val_loss: 5.0133e-04\n",
      "Epoch 00004: early stopping\n",
      "a4h_10mma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.685</td>\n",
       "      <td>28.454</td>\n",
       "      <td>0.157</td>\n",
       "      <td>1.059</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.224 0.685 28.454 0.157      1.059             0.254\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "           RUN NUMBER 2\n",
      "--------------------------------------\n",
      "##### Running on fold 0 #####\n",
      "Train on 13090 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00128, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 101s - loss: 0.0105 - val_loss: 0.0013\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00128\n",
      "13090/13090 - 87s - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00128 to 0.00119, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 89s - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00119 to 0.00117, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 87s - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00117 to 0.00117, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 87s - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00117 to 0.00111, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 89s - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00111 to 0.00109, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 88s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00109 to 0.00105, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 87s - loss: 9.7368e-04 - val_loss: 0.0011\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00105\n",
      "13090/13090 - 87s - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00105 to 0.00102, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 87s - loss: 9.5450e-04 - val_loss: 0.0010\n",
      "Epoch 11/16\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00102\n",
      "13090/13090 - 87s - loss: 9.7690e-04 - val_loss: 0.0011\n",
      "Epoch 12/16\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00102\n",
      "13090/13090 - 87s - loss: 9.4126e-04 - val_loss: 0.0010\n",
      "Epoch 13/16\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00102\n",
      "13090/13090 - 87s - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 00013: early stopping\n",
      "##### Running on fold 1 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00321, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 105s - loss: 0.0121 - val_loss: 0.0032\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00321 to 0.00244, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 92s - loss: 0.0010 - val_loss: 0.0024\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00244 to 0.00197, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 93s - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00197 to 0.00187, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 92s - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00187 to 0.00179, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 92s - loss: 9.5300e-04 - val_loss: 0.0018\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00179 to 0.00177, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 92s - loss: 9.8674e-04 - val_loss: 0.0018\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00177 to 0.00169, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 93s - loss: 9.3404e-04 - val_loss: 0.0017\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00169 to 0.00165, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 103s - loss: 9.0406e-04 - val_loss: 0.0016\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00165 to 0.00163, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 111s - loss: 8.7195e-04 - val_loss: 0.0016\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00163\n",
      "12994/12994 - 98s - loss: 8.7921e-04 - val_loss: 0.0017\n",
      "Epoch 11/16\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00163\n",
      "12994/12994 - 97s - loss: 8.5941e-04 - val_loss: 0.0017\n",
      "Epoch 12/16\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00163\n",
      "12994/12994 - 95s - loss: 8.2787e-04 - val_loss: 0.0016\n",
      "Epoch 00012: early stopping\n",
      "##### Running on fold 2 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00196, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 117s - loss: 0.0075 - val_loss: 0.0020\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00196 to 0.00187, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 106s - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00187 to 0.00146, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 100s - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00146\n",
      "12994/12994 - 104s - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00146\n",
      "12994/12994 - 103s - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00146\n",
      "12994/12994 - 101s - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 00006: early stopping\n",
      "##### Running on fold 3 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00129, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 118s - loss: 0.0159 - val_loss: 0.0013\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00129 to 0.00105, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 100s - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00105 to 0.00098, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 99s - loss: 0.0013 - val_loss: 9.8285e-04\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00098\n",
      "12994/12994 - 100s - loss: 0.0013 - val_loss: 9.8970e-04\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00098 to 0.00094, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 100s - loss: 0.0014 - val_loss: 9.3973e-04\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00094\n",
      "12994/12994 - 99s - loss: 0.0012 - val_loss: 9.8015e-04\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00094\n",
      "12994/12994 - 99s - loss: 0.0012 - val_loss: 9.8239e-04\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00094\n",
      "12994/12994 - 100s - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 00008: early stopping\n",
      "##### Running on fold 4 #####\n",
      "Train on 13088 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00038, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 118s - loss: 0.0049 - val_loss: 3.8331e-04\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00038\n",
      "13088/13088 - 107s - loss: 0.0013 - val_loss: 4.3182e-04\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00038\n",
      "13088/13088 - 108s - loss: 0.0015 - val_loss: 4.5331e-04\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00038 to 0.00034, saving model to output\\models\\a4h_10mhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 107s - loss: 0.0022 - val_loss: 3.3912e-04\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00034\n",
      "13088/13088 - 108s - loss: 0.0015 - val_loss: 4.2210e-04\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00034\n",
      "13088/13088 - 107s - loss: 0.0013 - val_loss: 3.5981e-04\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00034\n",
      "13088/13088 - 108s - loss: 0.0013 - val_loss: 3.5590e-04\n",
      "Epoch 00007: early stopping\n",
      "a4h_10mhbma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.215</td>\n",
       "      <td>0.599</td>\n",
       "      <td>26.262</td>\n",
       "      <td>0.156</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.215 0.599 26.262 0.156      1.021             0.261\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "           RUN NUMBER 3\n",
      "--------------------------------------\n",
      "##### Running on fold 0 #####\n",
      "Train on 13090 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00149, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 134s - loss: 0.0100 - val_loss: 0.0015\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00149 to 0.00119, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 110s - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00119 to 0.00117, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 110s - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00117 to 0.00113, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 110s - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00113 to 0.00111, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 111s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00111 to 0.00107, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 111s - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00107\n",
      "13090/13090 - 110s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00107 to 0.00101, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 111s - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00101 to 0.00101, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 110s - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00101\n",
      "13090/13090 - 110s - loss: 9.7756e-04 - val_loss: 0.0010\n",
      "Epoch 11/16\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00101 to 0.00100, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f0.h5\n",
      "13090/13090 - 110s - loss: 9.8963e-04 - val_loss: 0.0010\n",
      "Epoch 12/16\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00100\n",
      "13090/13090 - 110s - loss: 9.5280e-04 - val_loss: 0.0010\n",
      "Epoch 13/16\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00100\n",
      "13090/13090 - 110s - loss: 9.9876e-04 - val_loss: 0.0010\n",
      "Epoch 14/16\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00100\n",
      "13090/13090 - 110s - loss: 9.4239e-04 - val_loss: 0.0010\n",
      "Epoch 00014: early stopping\n",
      "##### Running on fold 1 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00288, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 133s - loss: 0.0108 - val_loss: 0.0029\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00288 to 0.00202, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 117s - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00202 to 0.00172, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 116s - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00172 to 0.00166, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 116s - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00166\n",
      "12994/12994 - 116s - loss: 9.8449e-04 - val_loss: 0.0017\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00166 to 0.00160, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 116s - loss: 9.7080e-04 - val_loss: 0.0016\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00160\n",
      "12994/12994 - 116s - loss: 9.6367e-04 - val_loss: 0.0016\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00160 to 0.00159, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 116s - loss: 9.4228e-04 - val_loss: 0.0016\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00159\n",
      "12994/12994 - 117s - loss: 9.1886e-04 - val_loss: 0.0016\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00159 to 0.00158, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 117s - loss: 9.4405e-04 - val_loss: 0.0016\n",
      "Epoch 11/16\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00158 to 0.00158, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 116s - loss: 9.0203e-04 - val_loss: 0.0016\n",
      "Epoch 12/16\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00158\n",
      "12994/12994 - 116s - loss: 9.3329e-04 - val_loss: 0.0016\n",
      "Epoch 13/16\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00158\n",
      "12994/12994 - 117s - loss: 8.7333e-04 - val_loss: 0.0016\n",
      "Epoch 14/16\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00158 to 0.00158, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f1.h5\n",
      "12994/12994 - 117s - loss: 8.9933e-04 - val_loss: 0.0016\n",
      "Epoch 15/16\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00158\n",
      "12994/12994 - 116s - loss: 8.7116e-04 - val_loss: 0.0016\n",
      "Epoch 16/16\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00158\n",
      "12994/12994 - 116s - loss: 8.7002e-04 - val_loss: 0.0016\n",
      "##### Running on fold 2 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00246, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 139s - loss: 0.0141 - val_loss: 0.0025\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00246 to 0.00170, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 120s - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00170\n",
      "12994/12994 - 119s - loss: 0.0014 - val_loss: 17423424.3189\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00170 to 0.00162, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 119s - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00162 to 0.00142, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 119s - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00142\n",
      "12994/12994 - 120s - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00142 to 0.00139, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 118s - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00139\n",
      "12994/12994 - 119s - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00139 to 0.00136, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 119s - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00136 to 0.00136, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 118s - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/16\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00136\n",
      "12994/12994 - 120s - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 12/16\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00136 to 0.00135, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 119s - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 13/16\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00135\n",
      "12994/12994 - 119s - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 14/16\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00135\n",
      "12994/12994 - 119s - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 15/16\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00135 to 0.00132, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f2.h5\n",
      "12994/12994 - 119s - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 16/16\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00132\n",
      "12994/12994 - 121s - loss: 0.0011 - val_loss: 0.0014\n",
      "##### Running on fold 3 #####\n",
      "Train on 12994 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00118, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 141s - loss: 0.0115 - val_loss: 0.0012\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00118\n",
      "12994/12994 - 127s - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00118\n",
      "12994/12994 - 128s - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00118 to 0.00115, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f3.h5\n",
      "12994/12994 - 129s - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00115\n",
      "12994/12994 - 128s - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00115\n",
      "12994/12994 - 129s - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00115\n",
      "12994/12994 - 128s - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 00007: early stopping\n",
      "##### Running on fold 4 #####\n",
      "Train on 13088 samples, validate on 1552 samples\n",
      "Epoch 1/16\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00076, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 150s - loss: 0.0079 - val_loss: 7.5847e-04\n",
      "Epoch 2/16\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00076 to 0.00049, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 128s - loss: 0.0018 - val_loss: 4.8562e-04\n",
      "Epoch 3/16\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00049 to 0.00043, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 127s - loss: 0.0015 - val_loss: 4.2767e-04\n",
      "Epoch 4/16\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00043\n",
      "13088/13088 - 126s - loss: 0.0019 - val_loss: 6.6173e-04\n",
      "Epoch 5/16\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00043 to 0.00037, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 127s - loss: 0.0014 - val_loss: 3.7009e-04\n",
      "Epoch 6/16\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00037 to 0.00036, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 129s - loss: 0.0013 - val_loss: 3.6270e-04\n",
      "Epoch 7/16\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00036 to 0.00033, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 129s - loss: 0.0012 - val_loss: 3.3270e-04\n",
      "Epoch 8/16\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00033 to 0.00032, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 127s - loss: 0.0012 - val_loss: 3.1986e-04\n",
      "Epoch 9/16\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00032 to 0.00030, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 127s - loss: 0.0012 - val_loss: 2.9577e-04\n",
      "Epoch 10/16\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00030 to 0.00029, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 127s - loss: 0.0012 - val_loss: 2.9367e-04\n",
      "Epoch 11/16\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00029 to 0.00028, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 128s - loss: 0.0012 - val_loss: 2.8192e-04\n",
      "Epoch 12/16\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00028 to 0.00028, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 127s - loss: 0.0012 - val_loss: 2.7815e-04\n",
      "Epoch 13/16\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00028 to 0.00028, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 127s - loss: 0.0012 - val_loss: 2.7798e-04\n",
      "Epoch 14/16\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00028 to 0.00027, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 127s - loss: 0.0011 - val_loss: 2.6938e-04\n",
      "Epoch 15/16\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00027\n",
      "13088/13088 - 127s - loss: 0.0012 - val_loss: 2.7000e-04\n",
      "Epoch 16/16\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00027 to 0.00027, saving model to output\\models\\a4h_10mfolddirhbma0_lb12h_lstm1_f4.h5\n",
      "13088/13088 - 128s - loss: 0.0011 - val_loss: 2.6599e-04\n",
      "a4h_10mfolddirhbma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.201</td>\n",
       "      <td>0.794</td>\n",
       "      <td>26.816</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.201 0.794 26.816 0.143      0.995             0.238\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "           RUN NUMBER 4\n",
      "--------------------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ma_hs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ma_hs'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-23dde9ece3b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"           RUN NUMBER {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--------------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mfolds_run_results_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmulti_func_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mfolds_run_results_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"run_config\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mrun_description_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfolds_run_results_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"run_params\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesc_str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-ea9baebb5740>\u001b[0m in \u001b[0;36mmulti_func_run\u001b[1;34m(data, target_col, col_names_and_offsets, input_data_str_repr, pred_forward_hrs, look_back_hrs, time_sample_res_minutes)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdownsample_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownsample_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLoad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_df_for_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_names_and_offsets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mphys_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrun_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphys_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     pre = Process.PreprocessData(steps_back=run_params.train_steps, \\\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ma_hs'"
     ]
    }
   ],
   "source": [
    "all_results_dicts = collections.OrderedDict()\n",
    "for i, all_args in enumerate(run_config_dicts_list):\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"           RUN NUMBER {}\".format(i+1))\n",
    "    print(\"--------------------------------------\")\n",
    "    folds_run_results_dict = multi_func_run(full_data, **all_args);\n",
    "    folds_run_results_dict[\"run_config\"] = all_args\n",
    "    run_description_str = folds_run_results_dict[\"run_params\"].desc_str\n",
    "    save_directory = osp.join(OUTPUT_BASE_DIR, \"pickle\", \"model_forward_scen_1\")\n",
    "    # tensorflow is not letting model be saved in dictionary with pickle\n",
    "    # so this is a workaround\n",
    "    for fold_data in folds_run_results_dict[\"folds_dict\"].values():\n",
    "        saved_model_file_name = run_description_str + \"_model_fold_{}.h5\".format(\n",
    "                                fold_data['fold_num'])\n",
    "        fold_data['model'].save(osp.join(save_directory, \"models\",\n",
    "                            saved_model_file_name))\n",
    "        del fold_data['model']\n",
    "        fold_data['model_filename'] = saved_model_file_name\n",
    "    with open(osp.join(save_directory, run_description_str + \".pkl\"), \"wb\") as f:\n",
    "        pickle.dump(folds_run_results_dict, f)\n",
    "    all_results_dicts[run_description_str] = folds_run_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:26:41.378655Z",
     "start_time": "2019-10-10T16:26:30.757440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4h_10mma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.215</td>\n",
       "      <td>0.649</td>\n",
       "      <td>27.949</td>\n",
       "      <td>0.158</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.215 0.649 27.949 0.158      1.004             0.258\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.685</td>\n",
       "      <td>28.454</td>\n",
       "      <td>0.157</td>\n",
       "      <td>1.059</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.224 0.685 28.454 0.157      1.059             0.254\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "a4h_10mhbma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.212</td>\n",
       "      <td>0.690</td>\n",
       "      <td>26.758</td>\n",
       "      <td>0.153</td>\n",
       "      <td>1.005</td>\n",
       "      <td>0.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.212 0.690 26.758 0.153      1.005             0.251\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.215</td>\n",
       "      <td>0.599</td>\n",
       "      <td>26.262</td>\n",
       "      <td>0.156</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.215 0.599 26.262 0.156      1.021             0.261\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "a4h_10mfolddirhbma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.199</td>\n",
       "      <td>0.806</td>\n",
       "      <td>26.838</td>\n",
       "      <td>0.138</td>\n",
       "      <td>1.003</td>\n",
       "      <td>0.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.199 0.806 26.838 0.138      1.003             0.231\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.201</td>\n",
       "      <td>0.794</td>\n",
       "      <td>26.816</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.201 0.794 26.816 0.143      0.995             0.238\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for mod_name in first_run_results.keys():\n",
    "    print(mod_name)\n",
    "    try:\n",
    "        display(first_run_results[mod_name][\"results_test\"].groupby(level=1).mean().loc[:,\n",
    "            ['rmse', 'r2', 'si', 'mae', 'max_error', 'my_weighted_rmse']])\n",
    "        display(all_results_dicts[mod_name][\"results_test\"].groupby(level=1).mean().loc[:,\n",
    "            ['rmse', 'r2', 'si', 'mae', 'max_error', 'my_weighted_rmse']])\n",
    "        print(\"--------------------\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-05T19:02:23.421017Z",
     "start_time": "2019-10-05T19:02:23.227679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4h_10mma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.685</td>\n",
       "      <td>28.454</td>\n",
       "      <td>0.157</td>\n",
       "      <td>1.059</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.224 0.685 28.454 0.157      1.059             0.254\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4h_10mhbma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.215</td>\n",
       "      <td>0.599</td>\n",
       "      <td>26.262</td>\n",
       "      <td>0.156</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.215 0.599 26.262 0.156      1.021             0.261\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4h_10mfolddirhbma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.201</td>\n",
       "      <td>0.794</td>\n",
       "      <td>26.816</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.201 0.794 26.816 0.143      0.995             0.238\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for mod_name in all_results_dicts.keys():\n",
    "    print(mod_name)\n",
    "    display(all_results_dicts[mod_name][\"results_test\"].groupby(level=1).mean().loc[:,\n",
    "        ['rmse', 'r2', 'si', 'mae', 'max_error', 'my_weighted_rmse']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T23:15:58.653634Z",
     "start_time": "2019-10-03T23:15:58.532305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4h_10mma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.685</td>\n",
       "      <td>28.454</td>\n",
       "      <td>0.157</td>\n",
       "      <td>1.059</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.224 0.685 28.454 0.157      1.059             0.254\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4h_10mhbma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.215</td>\n",
       "      <td>0.599</td>\n",
       "      <td>26.262</td>\n",
       "      <td>0.156</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.215 0.599 26.262 0.156      1.021             0.261\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4h_10mfolddirhbma0_lb12h_lstm1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>si</th>\n",
       "      <th>mae</th>\n",
       "      <th>max_error</th>\n",
       "      <th>my_weighted_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Const_Guess</th>\n",
       "      <td>0.183</td>\n",
       "      <td>0.846</td>\n",
       "      <td>28.660</td>\n",
       "      <td>0.110</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>0.201</td>\n",
       "      <td>0.794</td>\n",
       "      <td>26.816</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WW3</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.534</td>\n",
       "      <td>29.126</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rmse    r2     si   mae  max_error  my_weighted_rmse\n",
       "Const_Guess 0.183 0.846 28.660 0.110      1.040             0.219\n",
       "ML          0.201 0.794 26.816 0.143      0.995             0.238\n",
       "WW3         0.272 0.534 29.126 0.217      0.895             0.398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for mod_name in old_results_dict.keys():\n",
    "    print(mod_name)\n",
    "    display(all_results_dicts[mod_name][\"results_test\"].groupby(level=1).mean().loc[:,\n",
    "        ['rmse', 'r2', 'si', 'mae', 'max_error', 'my_weighted_rmse']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Advanced.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "358.25px",
    "left": "1993px",
    "top": "624.156px",
    "width": "274.047px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
