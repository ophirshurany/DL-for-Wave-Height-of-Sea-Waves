{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:20:25.072927Z",
     "start_time": "2019-05-31T22:20:24.857297Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T07:40:34.854730Z",
     "start_time": "2019-07-02T07:40:34.851681Z"
    }
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import Process\n",
    "import Load\n",
    "import Eval\n",
    "import Models\n",
    "import Split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pickle\n",
    "import os.path as osp\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T07:40:36.103681Z",
     "start_time": "2019-07-02T07:40:36.101816Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T07:40:37.271924Z",
     "start_time": "2019-07-02T07:40:37.269902Z"
    }
   },
   "outputs": [],
   "source": [
    "CONF_FILE_NAME = \"run_conf.ini\"\n",
    "conf = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T07:40:38.783591Z",
     "start_time": "2019-07-02T07:40:38.779800Z"
    }
   },
   "outputs": [],
   "source": [
    "conf.read(CONF_FILE_NAME)\n",
    "\n",
    "ADCP_PREF = conf['Pref']['ADCP_PREF']\n",
    "BUOY_PREF = conf['Pref']['BUOY_PREF']\n",
    "PHYS_DEEP_PREF = conf['Pref']['PHYS_DEEP_PREF']\n",
    "PHYS_SHALLOW_PREF = conf['Pref']['PHYS_SHALLOW_PREF']\n",
    "\n",
    "files_and_pref = [\\\n",
    "    [conf['Path']['ADCP'], conf['Pref']['ADCP_PREF']],\n",
    "    [conf['Path']['BUOY'], conf['Pref']['BUOY_PREF']],\n",
    "    [conf['Path']['MODEL_DEEP'], conf['Pref']['PHYS_DEEP_PREF']],\n",
    "    [conf['Path']['MODEL_SHALLOW'], conf['Pref']['PHYS_SHALLOW_PREF']]\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T07:40:48.005967Z",
     "start_time": "2019-07-02T07:40:40.850850Z"
    }
   },
   "outputs": [],
   "source": [
    "full_data = Load.load_all_data(files_and_pref, conf['Path']['DATA_BASE_DIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T08:08:11.166702Z",
     "start_time": "2019-06-27T08:08:11.137329Z"
    }
   },
   "outputs": [],
   "source": [
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T07:41:51.770687Z",
     "start_time": "2019-07-02T07:41:51.764888Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def downsample_data(data, ratio_for_downsample=2):\n",
    "    return data.iloc[range(0, data.shape[0], ratio_for_downsample)]\n",
    "\n",
    "# data = downsample_data(full_data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## AMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x=full_data.a_hs\n",
    "y=full_data.b_hs\n",
    "from sklearn import metrics\n",
    "metrics.adjusted_mutual_info_score(x, y,average_method='arithmetic')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T07:51:05.047423Z",
     "start_time": "2019-06-30T07:51:05.024939Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hs_ami=metrics.normalized_mutual_info_score(full_data.a_hs, full_data.b_hs,average_method='arithmetic')\n",
    "Tm_ami=metrics.normalized_mutual_info_score(full_data.a_Tm, full_data.b_Tm,average_method='arithmetic')\n",
    "dir_ami=metrics.normalized_mutual_info_score(full_data.a_dir, full_data.b_dir,average_method='arithmetic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T08:01:50.288144Z",
     "start_time": "2019-06-30T08:01:49.548795Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"hs\",hs_ami,\"Tm\",Tm_ami,\"dir\",dir_ami)\n",
    "plt.figure(1)\n",
    "plt.plot(full_data.b_hs,'r.')\n",
    "plt.plot(full_data.a_hs,'b.')\n",
    "plt.legend([\"Buoy\",\"ADCP\"])\n",
    "plt.title(\"hs\")\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(full_data.b_Tm,'r.')\n",
    "plt.plot(full_data.a_Tm,'b.')\n",
    "plt.legend([\"Buoy\",\"ADCP\"])\n",
    "plt.title(\"Tm\")\n",
    "\n",
    "plt.figure(3)\n",
    "plt.plot(full_data.b_dir,'r.')\n",
    "plt.plot(full_data.a_dir,'b.')\n",
    "plt.legend([\"Buoy\",\"ADCP\"])\n",
    "plt.title(\"dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T08:02:31.957741Z",
     "start_time": "2019-06-30T08:02:31.551724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adcp_hs_Tm_ami=metrics.normalized_mutual_info_score(full_data.a_hs, full_data.a_Tm,average_method='arithmetic')\n",
    "adcp_hs_dir_ami=metrics.normalized_mutual_info_score(full_data.a_hs, full_data.a_dir,average_method='arithmetic')\n",
    "adcp_Tm_dir_ami=metrics.normalized_mutual_info_score(full_data.a_Tm, full_data.a_dir,average_method='arithmetic')\n",
    "\n",
    "print(\"adcp:\",\"hs-Tm\",adcp_hs_Tm_ami,\"hs-dir\",adcp_hs_dir_ami,\"Tm-dir\",adcp_Tm_dir_ami)\n",
    "\n",
    "plt.plot(full_data.a_hs/max(full_data.a_hs),'r.')\n",
    "plt.plot(full_data.a_Tm/max(full_data.a_Tm),'b.')\n",
    "plt.plot(full_data.a_dir/max(full_data.a_dir),'g.')\n",
    "plt.legend([\"hs\",\"Tm\",\"dir\"])\n",
    "plt.title(\"ADCP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T07:59:35.727874Z",
     "start_time": "2019-06-30T07:59:35.139175Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buoy_hs_Tm_ami=metrics.normalized_mutual_info_score(full_data.b_hs, full_data.b_Tm,average_method='arithmetic')\n",
    "buoy_hs_dir_ami=metrics.normalized_mutual_info_score(full_data.b_hs, full_data.b_dir,average_method='arithmetic')\n",
    "buoy_Tm_dir_ami=metrics.normalized_mutual_info_score(full_data.b_Tm, full_data.b_dir,average_method='arithmetic')\n",
    "\n",
    "print(\"buoy:\",\"hs-Tm\",buoy_hs_Tm_ami,\"hs-dir\",buoy_hs_dir_ami,\"Tm-dir\",buoy_Tm_dir_ami)\n",
    "\n",
    "plt.plot(full_data.b_hs/max(full_data.b_hs),'r.')\n",
    "plt.plot(full_data.b_Tm/max(full_data.b_Tm),'b.')\n",
    "plt.plot(full_data.b_dir/max(full_data.b_dir),'g.')\n",
    "plt.legend([\"hs\",\"Tm\",\"dir\"])\n",
    "plt.title(\"Buoy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T09:08:53.203162Z",
     "start_time": "2019-06-30T09:08:53.191623Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buoy_hs_adcp_dir_ami=metrics.normalized_mutual_info_score(full_data.a_dir, full_data.b_hs,average_method='arithmetic')\n",
    "buoy_hs_adcp_dir_ami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T07:30:32.654540Z",
     "start_time": "2019-07-01T07:30:32.466706Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nmi_test=np.zeros(48) # np.array([1,2,3,4,5,5,6],dtype=np.float64)\n",
    "for i in range(48):\n",
    "    dt=6\n",
    "    hrs=(i+1)/2\n",
    "    x=full_data.b_hs[:-int(dt*hrs)]\n",
    "    y=full_data.a_hs[int(dt*hrs):]\n",
    "    nmi_test[i]=metrics.normalized_mutual_info_score(x, y,average_method='arithmetic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T07:30:34.628759Z",
     "start_time": "2019-07-01T07:30:34.527774Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(nmi_test)\n",
    "plt.plot(nmi_test,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T09:39:11.831524Z",
     "start_time": "2019-06-30T09:39:11.825119Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T09:29:51.032992Z",
     "start_time": "2019-06-30T09:29:51.030483Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Test data relations (AMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T07:00:43.049806Z",
     "start_time": "2019-06-30T07:00:42.085738Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# estimate probability density func (scott,1992)\n",
    "from sklearn.neighbors import KernelDensity\n",
    "# Gaussian KDE\n",
    "X=np.array(full_data.a_Tm)[:, np.newaxis]\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.75).fit(X)\n",
    "X_plot = np.linspace(1, max(full_data.a_Tm),1000)[:, np.newaxis]\n",
    "log_dens = kde.score_samples(X_plot)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "ax[0, 0].fill(X_plot[:, 0], np.exp(log_dens), fc='#AAAAFF')\n",
    "ax[0, 0].text(-3.5, 0.31, \"Gaussian Kernel Density\")\n",
    "\n",
    "\n",
    "\n",
    "for axi in ax.ravel():\n",
    "    axi.plot(X[:, 0], np.full(X.shape[0], -0.01), '+k')\n",
    "    axi.set_xlim(1, 20)\n",
    "    axi.set_ylim(-0.02, 0.34)\n",
    "\n",
    "for axi in ax[:, 0]:\n",
    "    axi.set_ylabel('Normalized Density')\n",
    "\n",
    "for axi in ax[1, :]:\n",
    "    axi.set_xlabel('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T07:00:50.003456Z",
     "start_time": "2019-06-30T07:00:49.906293Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.fill(X_plot[:, 0], np.exp(log_dens), fc='#AAAAFF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T07:30:25.491382Z",
     "start_time": "2019-06-30T07:30:23.215960Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# estimate probability density func (scott,1992)\n",
    "from sklearn.neighbors import KernelDensity\n",
    "# Gaussian KDE\n",
    "x=full_data.a_hs\n",
    "y=full_data.b_hs\n",
    "\n",
    "X=np.array(x)[:, np.newaxis]\n",
    "Y=np.array(y)[:, np.newaxis]\n",
    "X_kde = KernelDensity(kernel='gaussian', bandwidth=0.75).fit(X)\n",
    "Y_kde = KernelDensity(kernel='gaussian', bandwidth=0.75).fit(Y)\n",
    "X_plot = np.linspace(1, max(x),1000)[:, np.newaxis]\n",
    "Y_plot = np.linspace(1, max(y),1000)[:, np.newaxis]\n",
    "X_dens =  np.exp(X_kde.score_samples(X_plot))\n",
    "Y_dens =  np.exp(Y_kde.score_samples(Y_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T07:27:53.789969Z",
     "start_time": "2019-06-30T07:27:53.784953Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def kde2D(x, y, bandwidth, xbins=100j, ybins=100j, **kwargs): \n",
    "    \"\"\"Build 2D kernel density estimate (KDE).\"\"\"\n",
    "\n",
    "    # create grid of sample locations (default: 100x100)\n",
    "    xx, yy = np.mgrid[x.min():x.max():xbins, \n",
    "                      y.min():y.max():ybins]\n",
    "\n",
    "    xy_sample = np.vstack([yy.ravel(), xx.ravel()]).T\n",
    "    xy_train  = np.vstack([y, x]).T\n",
    "\n",
    "    kde_skl = KernelDensity(bandwidth=bandwidth, **kwargs)\n",
    "    kde_skl.fit(xy_train)\n",
    "\n",
    "    # score_samples() returns the log-likelihood of the samples\n",
    "    z = np.exp(kde_skl.score_samples(xy_sample))\n",
    "    return xx, yy, np.reshape(z, xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T07:29:00.483699Z",
     "start_time": "2019-06-30T07:28:49.441023Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "xx, yy, zz = kde2D(x, y, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T07:29:00.714771Z",
     "start_time": "2019-06-30T07:29:00.485235Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(xx, yy, zz)\n",
    "plt.scatter(x, y, s=2, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T07:31:51.661996Z",
     "start_time": "2019-06-30T07:31:51.653935Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zz/(X_dens*Y_dens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T07:38:29.212446Z",
     "start_time": "2019-06-30T07:38:29.163299Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data types and offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T07:40:59.340166Z",
     "start_time": "2019-07-02T07:40:59.320418Z"
    }
   },
   "outputs": [],
   "source": [
    "# choose relevant columns, get data_df and model data\n",
    "PRED_FORWARD = 6*12  # 6 bins per hour, 3 hours\n",
    "TARGET_COL = ADCP_PREF + \"_hs\"\n",
    "TARGET_COL = BUOY_PREF + \"_hs\"\n",
    "if TARGET_COL.startswith(ADCP_PREF):\n",
    "    PHYS_COL = PHYS_DEEP_PREF + \"_hs\"\n",
    "elif TARGET_COL.startswith(BUOY_PREF):\n",
    "    PHYS_COL = PHYS_SHALLOW_PREF + \"_hs\"\n",
    "else:\n",
    "    raise(IndexError)\n",
    "IS_TARGET_DATA_SOURCE_INCLUDED = True\n",
    "\n",
    "# col_names_and_offsets = np.array([(ADCP_PREF+\"_hs\", 0), (PHYS_DEEP_PREF+\"_hs\", GAP_FORWARD), (PHYS_SHALLOW_PREF+\"_hs\", 12)])\n",
    "# col_names_and_offsets = np.array([(ADCP_PREF+\"_hs\", 0), (PHYS_DEEP_PREF+\"_hs\", PRED_FORWARD)])\n",
    "# note: took out a_dir because it has \"inf\"\n",
    "# col_names_and_offsets = np.array(list(zip(['a_hs', 'b_hs', 'b_dir', 'ma_hs', 'ma_dir'], np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "# col_names_and_offsets = np.array(list(zip(['a_hs', 'a_dir'], np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "col_names_and_offsets = np.array(list(zip(['a_hs', 'b_dir', 'b_hs'], np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "col_names_and_offsets = np.array(list(zip(['b_hs', 'b_dir'], np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "# col_names_and_offsets = np.array([(PHYS_DEEP_PREF+\"_hs\", PRED_FORWARD), (ADCP_PREF+\"_hs\", 0)])\n",
    "df = Load.get_df_for_model(data, col_names_and_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T20:38:52.101789Z",
     "start_time": "2019-05-27T20:38:52.086161Z"
    }
   },
   "outputs": [],
   "source": [
    "# assume that target is aligned as starting at 0 (with no offset)\n",
    "# and then just cut off edge which exists in the case when some offsets aren't 0\n",
    "phys_target = data[PHYS_COL].iloc[:df.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train-val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T20:38:52.829953Z",
     "start_time": "2019-05-27T20:38:52.813605Z"
    }
   },
   "outputs": [],
   "source": [
    "train, val, test, phys_test = Split.split_train_test_val(df, phys_target=phys_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T22:24:24.097145Z",
     "start_time": "2019-05-27T22:24:24.075015Z"
    }
   },
   "outputs": [],
   "source": [
    "train, val, test, phys_test = Split.kfold_split_train_test(df, 2, phys_target=phys_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess (scale, restructure into sequences and reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:21:52.980946Z",
     "start_time": "2019-05-31T22:21:52.964228Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_feature_and_target_data(data, target_col_name, is_target_in_features=True):\n",
    "    if type(data) == list:\n",
    "        target = [d[[target_col_name]] for d in data]\n",
    "        if not is_target_in_features:\n",
    "            data = [d.drop(target_col_name, axis=1) for d in data]\n",
    "    else:\n",
    "        target = data[[target_col_name]]\n",
    "        if not is_target_in_features:\n",
    "            data = data.drop(target_col_name, axis=1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T22:21:04.508559Z",
     "start_time": "2019-05-27T22:21:04.490412Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_feature_and_target_data(data, target_col_name, is_target_in_features=True):\n",
    "#     if is_target_in_features:\n",
    "#         return data, data[[target_col_name]]\n",
    "#     else:\n",
    "#         if type(data) == list:\n",
    "#             data_no_target = [d.drop(target_col_name, axis=1) for d in data]\n",
    "#             target = [d[[target_col_name]] for d in data]\n",
    "#         else:\n",
    "#             data_no_target = data.drop(target_col_name, axis=1)\n",
    "#             target = data[[target_col_name]]\n",
    "#         return data_no_target, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T22:27:19.084375Z",
     "start_time": "2019-05-27T22:27:19.067142Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_STEPS = 12\n",
    "Y_LENGTH = 1\n",
    "STEP_SIZE = 1\n",
    "GAP_FORWARD = PRED_FORWARD # for now instead just predict 3 hours forward, sounds good\n",
    "pre = Process.PreprocessData(steps_back=TRAIN_STEPS, y_length=Y_LENGTH, step_size=STEP_SIZE,\n",
    "                          gap_forward=GAP_FORWARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T22:34:46.192617Z",
     "start_time": "2019-05-27T22:34:46.139546Z"
    }
   },
   "outputs": [],
   "source": [
    "pre.fit(*get_feature_and_target_data(train, TARGET_COL, IS_TARGET_DATA_SOURCE_INCLUDED))\n",
    "X_train, y_train = pre.transform(*get_feature_and_target_data(train, TARGET_COL, IS_TARGET_DATA_SOURCE_INCLUDED))\n",
    "X_val, y_val = pre.transform(*get_feature_and_target_data(val, TARGET_COL, IS_TARGET_DATA_SOURCE_INCLUDED))\n",
    "X_test, y_test = pre.transform(*get_feature_and_target_data(test, TARGET_COL, IS_TARGET_DATA_SOURCE_INCLUDED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose and build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T22:34:49.781952Z",
     "start_time": "2019-05-27T22:34:49.667374Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[2]\n",
    "model_structure_args = {\"look_back\": TRAIN_STEPS, \"input_dimension\": input_dim}\n",
    "model_train_args = {\"num_epochs\" : 8, \"batch_size\": 50}\n",
    "# model_class = Models.LSTMModel\n",
    "model_class = Models.FCNNModel\n",
    "# model_class = Models.RandomForestModel\n",
    "\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    curr_model = model_class(**model_structure_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T22:34:55.093318Z",
     "start_time": "2019-05-27T22:34:52.011465Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    curr_model.fit(X_train, y_train, val_data=(X_val, y_val), **model_train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T22:35:01.493241Z",
     "start_time": "2019-05-27T22:35:00.513527Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = curr_model.predict(X_test)\n",
    "\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get originally scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T22:35:02.002634Z",
     "start_time": "2019-05-27T22:35:01.986239Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_org = pre.inverse_scale_target(y_pred)\n",
    "test_org = pre.inverse_scale_target(y_test.reshape(-1, 1))\n",
    "phys_org = phys_test.iloc[TRAIN_STEPS + PRED_FORWARD:].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T22:35:03.366406Z",
     "start_time": "2019-05-27T22:35:03.346740Z"
    }
   },
   "outputs": [],
   "source": [
    "results = Eval.eval_pred_phys_const(test_org, pred_org, phys_org, pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T20:38:09.506746Z",
     "start_time": "2019-05-27T20:38:09.486203Z"
    }
   },
   "outputs": [],
   "source": [
    "results[['rmse', 'r2', 'si', 'max_error']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T18:44:53.115984Z",
     "start_time": "2019-05-27T18:44:53.100006Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(pred_org.shape[0]), test_org, 'g.')\n",
    "# plt.plot(range(preds_org.shape[0]), np.concatenate([test_org[18:],np.zeros((18, 1))]), 'y')\n",
    "plt.plot(range(pred_org.shape[0]), pred_org, 'b')\n",
    "plt.plot(range(pred_org.shape[0]), phys_org, 'r')\n",
    "plt.legend(['Buoy/ADCP', '{} Prediction'.format(curr_model.name), 'WW3'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kfold functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T05:25:23.318283Z",
     "start_time": "2019-06-01T05:25:23.292455Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_single_fold_train_test(df, target_col, is_target_in_input,\n",
    "                               phys_target, pre, model_class, model_train_args, fold_num, k=5):\n",
    "    train, val, test, phys_test = Split.kfold_split_train_test(df, fold_num,\n",
    "                                                k=k, phys_target=phys_target)\n",
    "\n",
    "    pre.fit(*get_feature_and_target_data(train, target_col, is_target_in_input))\n",
    "    X_train, y_train = pre.transform(*get_feature_and_target_data(train, target_col, is_target_in_input))\n",
    "    X_val, y_val = pre.transform(*get_feature_and_target_data(val, target_col, is_target_in_input))\n",
    "    X_test, y_test = pre.transform(*get_feature_and_target_data(test, target_col, is_target_in_input))\n",
    "\n",
    "    input_dim = X_train.shape[2]\n",
    "    model_structure_args = {\"look_back\": TRAIN_STEPS, \"input_dimension\": input_dim,\n",
    "                           \"description_string\": DESC_STR + \"_f{}\".format(fold_num)}\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        curr_model = model_class(**model_structure_args)\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        curr_model.fit(X_train, y_train, val_data=(X_val, y_val), **model_train_args)\n",
    "\n",
    "    y_pred = curr_model.predict(X_test)\n",
    "\n",
    "    pred_org = pre.inverse_scale_target(y_pred)\n",
    "    test_org = pre.inverse_scale_target(y_test.reshape(-1, 1))\n",
    "    phys_org = phys_test.iloc[TRAIN_STEPS + PRED_FORWARD:].values.reshape(-1,1)\n",
    "\n",
    "    results = Eval.eval_pred_phys_const(test_org, pred_org, phys_org, pre)\n",
    "    return results\n",
    "\n",
    "def run_kfold_train_test(df, target_col, is_target_in_input, phys_target, pre,\n",
    "                         model_class, model_train_args, k=5, num_folds_to_run=None):\n",
    "    results = []\n",
    "    folds_to_run_on = list(range(k))\n",
    "    if num_folds_to_run:\n",
    "    # if num_folds_to_run < k, prefer running on last folds\n",
    "        folds_to_run_on = folds_to_run_on[-num_folds_to_run:]\n",
    "    for i in folds_to_run_on:\n",
    "        print(\"Running on fold {}\".format(i))\n",
    "        curr_fold_results = run_single_fold_train_test(df, target_col, is_target_in_input, phys_target, pre,\n",
    "                                            model_class, model_train_args, fold_num=i, k=k).assign(fold=i)\n",
    "        results.append(curr_fold_results)\n",
    "    results = pd.concat(results)\n",
    "    results = results.set_index(['fold', results.index])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Cell to rule them all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Old Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# PRED_FORWARD_HRS = 6\n",
    "# LOOK_BACK_HRS = 12\n",
    "# TIME_SAMPLE_RES_MINUTES = 10\n",
    "# k = 5\n",
    "# num_folds_to_run = 5\n",
    "\n",
    "\n",
    "# samples_in_hr = 60 / TIME_SAMPLE_RES_MINUTES\n",
    "# downsample_ratio = TIME_SAMPLE_RES_MINUTES / 10\n",
    "# assert(samples_in_hr == int(samples_in_hr) and downsample_ratio == int(downsample_ratio))\n",
    "# samples_in_hr = int(samples_in_hr)\n",
    "# downsample_ratio = int(downsample_ratio)\n",
    "\n",
    "# data = downsample_data(full_data, downsample_ratio)\n",
    "\n",
    "# # col_names_and_offsets = np.array([(ADCP_PREF+\"_hs\", 0), (PHYS_DEEP_PREF+\"_hs\", GAP_FORWARD), (PHYS_SHALLOW_PREF+\"_hs\", 12)])\n",
    "# # col_names_and_offsets = np.array([(ADCP_PREF+\"_hs\", 0), (PHYS_DEEP_PREF+\"_hs\", PRED_FORWARD)])\n",
    "# # note: took out a_dir because it has \"inf\"\n",
    "# # col_names_and_offsets = np.array(list(zip(['a_hs', 'b_hs', 'b_dir', 'ma_hs', 'ma_dir'], np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "# # col_names_and_offsets = np.array(list(zip(['a_hs', 'a_dir'], np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "# # col_names_and_offsets = np.array(list(zip(['a_hs', 'b_dir', 'b_hs'], np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "# col_names_and_offsets = np.array(list(zip(['b_hs', 'b_dir'], np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "\n",
    "\n",
    "# DESC_STR = \"b{}h_{}msindirhb_lb{}h_lstm1\".format(PRED_FORWARD_HRS,\n",
    "#                                                 TIME_SAMPLE_RES_MINUTES, LOOK_BACK_HRS)\n",
    "\n",
    "# PRED_FORWARD = samples_in_hr * PRED_FORWARD_HRS\n",
    "# # TARGET_COL = ADCP_PREF + \"_hs\"\n",
    "# TARGET_COL = BUOY_PREF + \"_hs\"\n",
    "# if TARGET_COL.startswith(ADCP_PREF):\n",
    "#     PHYS_COL = PHYS_DEEP_PREF + \"_hs\"\n",
    "# elif TARGET_COL.startswith(BUOY_PREF):\n",
    "#     PHYS_COL = PHYS_SHALLOW_PREF + \"_hs\"\n",
    "# else:\n",
    "#     raise(IndexError)\n",
    "# IS_TARGET_DATA_SOURCE_INCLUDED = True\n",
    "\n",
    "\n",
    "\n",
    "# # col_names_and_offsets = np.array([(PHYS_DEEP_PREF+\"_hs\", PRED_FORWARD), (ADCP_PREF+\"_hs\", 0)])\n",
    "# df = Load.get_df_for_model(data, col_names_and_offsets)\n",
    "\n",
    "# phys_target = data[PHYS_COL].iloc[:df.shape[0]]\n",
    "\n",
    "\n",
    "# TRAIN_STEPS = samples_in_hr * LOOK_BACK_HRS\n",
    "# Y_LENGTH = 1\n",
    "# STEP_SIZE = 1\n",
    "# GAP_FORWARD = PRED_FORWARD # for now instead just predict 3 hours forward, sounds good\n",
    "# pre = Process.PreprocessData(steps_back=TRAIN_STEPS, y_length=Y_LENGTH, step_size=STEP_SIZE,\n",
    "#                           gap_forward=GAP_FORWARD)\n",
    "\n",
    "# model_train_args = {\"num_epochs\" : 15, \"batch_size\": 50}\n",
    "# model_class = Models.LSTMModel\n",
    "# # model_class = Models.FCNNModel\n",
    "# # model_class = Models.RandomForestModel\n",
    "\n",
    "\n",
    "# results_file_name = DESC_STR + \"_res\"\n",
    "\n",
    "# results = run_kfold_train_test(df, phys_target, k=k, num_folds_to_run=num_folds_to_run)\n",
    "\n",
    "# if k == num_folds_to_run:\n",
    "#     results_file_name = results_file_name + \".h5\"\n",
    "# else:\n",
    "#     results_file_name = \"{}_{}of{}_folds.h5\".format(results_file_name, num_folds_to_run, k)  \n",
    "\n",
    "# results.to_hdf(osp.join(\"output\", \"results\", results_file_name), key=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### New Old cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T07:40:10.174348Z",
     "start_time": "2019-06-01T07:40:10.136734Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def org_multi_func_run(*, pred_fwd, input_cols, descr_str):\n",
    "\n",
    "    PRED_FORWARD_HRS = pred_fwd\n",
    "    LOOK_BACK_HRS = 12\n",
    "    TIME_SAMPLE_RES_MINUTES = 10\n",
    "    k = 5\n",
    "    num_folds_to_run = 5\n",
    "\n",
    "\n",
    "    samples_in_hr = 60 / TIME_SAMPLE_RES_MINUTES\n",
    "    downsample_ratio = TIME_SAMPLE_RES_MINUTES / 10\n",
    "    assert(samples_in_hr == int(samples_in_hr) and downsample_ratio == int(downsample_ratio))\n",
    "    samples_in_hr = int(samples_in_hr)\n",
    "    downsample_ratio = int(downsample_ratio)\n",
    "\n",
    "    data = downsample_data(full_data, downsample_ratio)\n",
    "\n",
    "    # col_names_and_offsets = np.array([(ADCP_PREF+\"_hs\", 0), (PHYS_DEEP_PREF+\"_hs\", GAP_FORWARD), (PHYS_SHALLOW_PREF+\"_hs\", 12)])\n",
    "    # col_names_and_offsets = np.array([(ADCP_PREF+\"_hs\", 0), (PHYS_DEEP_PREF+\"_hs\", PRED_FORWARD)])\n",
    "    # note: took out a_dir because it has \"inf\"\n",
    "    # col_names_and_offsets = np.array(list(zip(['a_hs', 'b_hs', 'b_dir', 'ma_hs', 'ma_dir'], np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "    # col_names_and_offsets = np.array(list(zip(['a_hs', 'a_dir'], np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "    # col_names_and_offsets = np.array(list(zip(['a_hs', 'b_dir', 'b_hs'], np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "    col_names_and_offsets = np.array(list(zip(input_cols, np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "\n",
    "\n",
    "#     DESC_STR = \"b{}h_{}msindirhb_lb{}h_lstm1\".format(PRED_FORWARD_HRS,\n",
    "#                                                     TIME_SAMPLE_RES_MINUTES, LOOK_BACK_HRS)\n",
    "    DESC_STR = descr_str.format(PRED_FORWARD_HRS,\n",
    "                                TIME_SAMPLE_RES_MINUTES, LOOK_BACK_HRS)\n",
    "\n",
    "    PRED_FORWARD = samples_in_hr * PRED_FORWARD_HRS\n",
    "    # TARGET_COL = ADCP_PREF + \"_hs\"\n",
    "    TARGET_COL = BUOY_PREF + \"_hs\"\n",
    "    if TARGET_COL.startswith(ADCP_PREF):\n",
    "        PHYS_COL = PHYS_DEEP_PREF + \"_hs\"\n",
    "    elif TARGET_COL.startswith(BUOY_PREF):\n",
    "        PHYS_COL = PHYS_SHALLOW_PREF + \"_hs\"\n",
    "    else:\n",
    "        raise(IndexError)\n",
    "    IS_TARGET_DATA_SOURCE_INCLUDED = True\n",
    "\n",
    "\n",
    "\n",
    "    # col_names_and_offsets = np.array([(PHYS_DEEP_PREF+\"_hs\", PRED_FORWARD), (ADCP_PREF+\"_hs\", 0)])\n",
    "    df = Load.get_df_for_model(data, col_names_and_offsets)\n",
    "\n",
    "    phys_target = data[PHYS_COL].iloc[:df.shape[0]]\n",
    "\n",
    "\n",
    "    TRAIN_STEPS = samples_in_hr * LOOK_BACK_HRS\n",
    "    Y_LENGTH = 1\n",
    "    STEP_SIZE = 1\n",
    "    GAP_FORWARD = PRED_FORWARD # for now instead just predict 3 hours forward, sounds good\n",
    "    pre = Process.PreprocessData(steps_back=TRAIN_STEPS, y_length=Y_LENGTH, step_size=STEP_SIZE,\n",
    "                              gap_forward=GAP_FORWARD)\n",
    "\n",
    "    model_train_args = {\"num_epochs\" : 16, \"batch_size\": 50}\n",
    "    model_class = Models.LSTMModel\n",
    "    # model_class = Models.FCNNModel\n",
    "    # model_class = Models.RandomForestModel\n",
    "\n",
    "\n",
    "    results_file_name = DESC_STR + \"_res\"\n",
    "\n",
    "    results = run_kfold_train_test(df, phys_target, pre,\n",
    "                        model_class, model_train_args, k=k, num_folds_to_run=num_folds_to_run)\n",
    "\n",
    "    if k == num_folds_to_run:\n",
    "        results_file_name = results_file_name + \".h5\"\n",
    "    else:\n",
    "        results_file_name = \"{}_{}of{}_folds.h5\".format(results_file_name, num_folds_to_run, k)  \n",
    "\n",
    "    results.to_hdf(osp.join(\"output\", \"results\", results_file_name), key=\"a\")\n",
    "    \n",
    "    pd.options.display.float_format = '{:,.3f}'.format\n",
    "    print(DESC_STR)\n",
    "    display(results.groupby(level=1).mean()[['rmse', 'r2', 'si', 'mae', 'max_error']])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Can hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T07:41:14.098223Z",
     "start_time": "2019-06-01T07:41:14.075746Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_single_fold_train_test(df, run_params, curr_fold_num):\n",
    "    phys_target = data[run_params.phys_col].iloc[:df.shape[0]]\n",
    "    train, val, test, phys_test = Split.kfold_split_train_test(df, curr_fold_num,\n",
    "                                                k=run_params.k, phys_target=phys_target)\n",
    "\n",
    "    run_params.pre.fit(*get_feature_and_target_data(\n",
    "        train, run_params.target_col, run_params.is_target_in_input))\n",
    "    X_train, y_train = run_params.pre.transform(\n",
    "        *get_feature_and_target_data(train,run_params.target_col, run_params.is_target_in_input))\n",
    "    X_val, y_val = run_params.pre.transform(\n",
    "        *get_feature_and_target_data(val, run_params.target_col, run_params.is_target_in_input))\n",
    "    X_test, y_test = run_params.pre.transform(\n",
    "        *get_feature_and_target_data(test, run_params.target_col, run_params.is_target_in_input))\n",
    "\n",
    "    input_dim = X_train.shape[2]\n",
    "    model_structure_args = {\"look_back\": run_params.train_steps, \"input_dimension\": input_dim,\n",
    "                           \"description_string\": run_params.desc_str + \"_f{}\".format(curr_fold_num)}\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        curr_model = run_params.model_class(**model_structure_args)\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        curr_model.fit(X_train, y_train, val_data=(X_val, y_val), **run_params.model_args)\n",
    "\n",
    "    y_pred = curr_model.predict(X_test)\n",
    "\n",
    "    pred_org = run_params.pre.inverse_scale_target(y_pred)\n",
    "    test_org = run_params.pre.inverse_scale_target(y_test.reshape(-1, 1))\n",
    "    phys_org = phys_test.iloc[run_params.train_steps + run_params.pred_forward:].values.reshape(-1,1)\n",
    "\n",
    "    results = Eval.eval_pred_phys_const(test_org, pred_org, phys_org, run_params.pre)\n",
    "    return results\n",
    "\n",
    "def run_kfold_train_test(df, run_params):\n",
    "    results = []\n",
    "    folds_to_run_on = list(range(run_params.k))\n",
    "    if run_params.num_folds_to_run:\n",
    "    # if num_folds_to_run < k, prefer running on last folds\n",
    "        folds_to_run_on = folds_to_run_on[-run_params.num_folds_to_run:]\n",
    "    for i in folds_to_run_on:\n",
    "        print(\"Running on fold {}\".format(i))\n",
    "        curr_fold_results = run_single_fold_train_test(df, run_params, i).assign(fold=i)\n",
    "        results.append(curr_fold_results)\n",
    "    results = pd.concat(results)\n",
    "    results = results.set_index(['fold', results.index])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T07:46:11.949090Z",
     "start_time": "2019-06-01T07:46:11.926645Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TestInstanceParams():\n",
    "    def __init__(self, input_data_str_repr, model_str_repr, desc_str_addition='',\n",
    "                 target_col=\"b_hs\", is_target_in_input=True,  pred_forward_hrs=4,\n",
    "                look_back_hrs=12, time_sample_res_minutes=10, model_class=Models.LSTMModel,\n",
    "                 model_args={\"num_epochs\" : 5, \"batch_size\": 50}, \n",
    "                 k=5, num_folds_to_run=None):\n",
    "        self.pre = None\n",
    "        self.target_col = target_col\n",
    "        self.is_target_in_input = is_target_in_input\n",
    "        self.pred_forward_hrs = pred_forward_hrs\n",
    "        self.look_back_hrs = look_back_hrs\n",
    "        self.time_res_min = time_sample_res_minutes\n",
    "\n",
    "        self.model_class = model_class\n",
    "        self.model_args = model_args\n",
    "        self.k = k\n",
    "        if not num_folds_to_run:\n",
    "            self.num_folds_to_run = k\n",
    "        else:\n",
    "            self.num_folds_to_run = num_folds_to_run\n",
    "\n",
    "        self.desc_str = self.build_desc_str(input_data_str_repr, model_str_repr, desc_str_addition)\n",
    "        self.phys_col = self.find_phys_col()\n",
    "        self.samples_in_hr = 60 / time_sample_res_minutes\n",
    "        self.downsample_ratio = time_sample_res_minutes / 10\n",
    "        assert(self.samples_in_hr == int(self.samples_in_hr) and \\\n",
    "               self.downsample_ratio == int(self.downsample_ratio))\n",
    "        self.samples_in_hr = int(self.samples_in_hr)\n",
    "        self.downsample_ratio = int(self.downsample_ratio)\n",
    "        self.pred_forward = self.pred_forward_hrs * self.samples_in_hr\n",
    "        self.train_steps = self.look_back_hrs*self.samples_in_hr\n",
    "    \n",
    "    def build_desc_str(self, input_data_str_repr, model_str_repr, addition):\n",
    "        if self.target_col.startswith(ADCP_PREF):\n",
    "            target_pref = ADCP_PREF\n",
    "        elif self.target_col.startswith(BUOY_PREF):\n",
    "            target_pref = BUOY_PREF\n",
    "        else:\n",
    "            raise IndexError\n",
    "        # desc_str is of format:\n",
    "        # <pred_target><forward hours>h_<time_res_min>m_lb<look_back hours>h_<model_name><optional addition>\n",
    "        desc_str = \"{}{}h_{}m{}_lb{}h_{}{}\".format(target_pref, self.pred_forward_hrs,\n",
    "                self.time_res_min, input_data_str_repr, self.look_back_hrs, model_str_repr, addition)\n",
    "        return desc_str\n",
    "\n",
    "    def set_pre(self, pre):\n",
    "        self.pre = pre\n",
    "    \n",
    "    def get_pre(self):\n",
    "        if not self.pre:\n",
    "            raise NameError('pre not initialized yet')\n",
    "        return self.pre\n",
    "    \n",
    "    def find_phys_col(self):\n",
    "        if self.target_col.startswith(ADCP_PREF):\n",
    "            phys_col = PHYS_DEEP_PREF + \"_hs\"\n",
    "        elif self.target_col.startswith(BUOY_PREF):\n",
    "            phys_col = PHYS_SHALLOW_PREF + \"_hs\"\n",
    "        else:\n",
    "            raise IndexError\n",
    "        return phys_col\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T23:36:56.521204Z",
     "start_time": "2019-06-01T23:36:56.501270Z"
    }
   },
   "outputs": [],
   "source": [
    "def multi_func_run(*, target_col, col_names_and_offsets, input_data_str_repr,\n",
    "                  pred_forward_hrs=4, look_back_hrs=12, time_sample_res_minutes=10):\n",
    "    \n",
    "    model_str_repr = 'lstm1'\n",
    "#     pred_forward_hrs = 6\n",
    "#     look_back_hrs = 12\n",
    "#     time_sample_res_minutes= 10\n",
    "    k = 5\n",
    "    num_folds_to_run = 5\n",
    "\n",
    "    \n",
    "    model_train_args = {\"num_epochs\" : 16, \"batch_size\": 50}\n",
    "    model_class = Models.LSTMModel\n",
    "    # model_class = Models.FCNNModel\n",
    "    # model_class = Models.RandomForestModel\n",
    "    \n",
    "    col_names_and_offsets = col_names_and_offsets*int(60/time_sample_res_minutes)\n",
    "    \n",
    "    is_target_in_input=True\n",
    "    if target_col not in col_names_and_offsets.index:\n",
    "        is_target_in_input = False\n",
    "        col_names_and_offsets[target_col] = 0\n",
    "\n",
    "    run_params = TestInstanceParams(input_data_str_repr=input_data_str_repr, \\\n",
    "        model_str_repr=model_str_repr, target_col=target_col, \\\n",
    "        is_target_in_input=is_target_in_input, pred_forward_hrs=pred_forward_hrs, \\\n",
    "        look_back_hrs=look_back_hrs, time_sample_res_minutes=time_sample_res_minutes, \\\n",
    "        k=k, num_folds_to_run=num_folds_to_run, \\\n",
    "        model_class=model_class, model_args=model_train_args, \\\n",
    "        desc_str_addition ='')\n",
    "    \n",
    "\n",
    "    # col_names_and_offsets = np.array([(ADCP_PREF+\"_hs\", 0), (PHYS_DEEP_PREF+\"_hs\", GAP_FORWARD), (PHYS_SHALLOW_PREF+\"_hs\", 12)])\n",
    "    # col_names_and_offsets = np.array([(ADCP_PREF+\"_hs\", 0), (PHYS_DEEP_PREF+\"_hs\", PRED_FORWARD)])\n",
    "    # note: took out a_dir because it has \"inf\"\n",
    "    # col_names_and_offsets = np.array(list(zip(['a_hs', 'b_hs', 'b_dir', 'ma_hs', 'ma_dir'], np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "    # col_names_and_offsets = np.array(list(zip(['a_hs', 'a_dir'], np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "    # col_names_and_offsets = np.array(list(zip(['a_hs', 'b_dir', 'b_hs'], np.zeros(data.columns.shape, dtype=np.int8))))\n",
    "    # TARGET_COL = ADCP_PREF + \"_hs\"\n",
    "    # TARGET_COL = BUOY_PREF + \"_hs\"\n",
    "    \n",
    "    data = downsample_data(full_data, run_params.downsample_ratio)\n",
    "    df = Load.get_df_for_model(data, col_names_and_offsets)\n",
    "\n",
    "    pre = Process.PreprocessData(steps_back=run_params.train_steps, \\\n",
    "                                 y_length=1, step_size=1, \\\n",
    "                              gap_forward=run_params.pred_forward)\n",
    "    run_params.set_pre(pre)\n",
    "    \n",
    "    results = run_kfold_train_test(df, run_params)\n",
    "    if run_params.k == run_params.num_folds_to_run:\n",
    "        results_file_name = run_params.desc_str + \"_res.h5\"\n",
    "    else:\n",
    "        results_file_name = \"{}_res_{}of{}_folds.h5\".format(run_params.desc_str,\n",
    "                                            run_params.num_folds_to_run, run_params.k)  \n",
    "    results.to_hdf(osp.join(\"output\", \"results\", results_file_name), key=\"a\")\n",
    "    \n",
    "    pd.options.display.float_format = '{:,.3f}'.format\n",
    "    print(run_params.desc_str)\n",
    "    display(results.groupby(level=1).mean()[['rmse', 'r2', 'si', 'mae', 'max_error']])\n",
    "    return results, results_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T08:04:03.669310Z",
     "start_time": "2019-06-01T08:04:03.653099Z"
    }
   },
   "outputs": [],
   "source": [
    "# run_1 = {\"pred_fwd\":4, \"input_cols\":['a_hs', 'b_hs', 'b_dir'], \"descr_str\":\"b{}h_{}mfolddirhbha_lb{}h_lstm1\"}\n",
    "# run_0 = {\"pred_fwd\":4, \"input_cols\":['a_hs', 'b_hs'], \"descr_str\":\"b{}h_{}mhahb_lb{}h_lstm1\"}\n",
    "# run_2 = {\"pred_fwd\":6, \"input_cols\":['b_hs'], \"descr_str\":\"b{}h_{}mhb_lb{}h_lstm1\"}\n",
    "# run_3 = {\"pred_fwd\":6, \"input_cols\":['a_hs', 'b_hs'], \"descr_str\":\"b{}h_{}mhahb_lb{}h_lstm1\"}\n",
    "# run_4 = {\"pred_fwd\":6, \"input_cols\":['b_dir', 'b_hs'], \"descr_str\":\"b{}h_{}mfolddirhb_lb{}h_lstm1\"}\n",
    "# run_5 = {\"pred_fwd\":6, \"input_cols\":['a_hs', 'b_hs', 'b_dir'], \"descr_str\":\"b{}h_{}mfolddirhbha_lb{}h_lstm1\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T08:08:28.432350Z",
     "start_time": "2019-06-01T08:08:28.410577Z"
    }
   },
   "outputs": [],
   "source": [
    "run_1 = {\"target_col\":'b_hs', \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['a_hs', 'b_hs'], data=[0,0]), \"pred_forward_hrs\":6,\n",
    "         \"input_data_str_repr\":'hahb'}\n",
    "run_2 = {\"target_col\":'b_hs', \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['a_hs', 'b_hs', 'b_dir'], data=[0,0, 0]), \"pred_forward_hrs\":6,\n",
    "         \"input_data_str_repr\":'folddirhbha'}\n",
    "run_3 = {\"target_col\":'b_hs', \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['a_hs', 'b_hs', 'b_dir'], data=[0,0, 0]), \"pred_forward_hrs\":4,\n",
    "         \"input_data_str_repr\":'folddirhbha'}\n",
    "run_4 = {\"target_col\":'b_hs', \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['a_hs', 'b_hs'], data=[0,0]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'hahb'}\n",
    "run_5 = {\"target_col\":'b_hs', \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir'], data=[0,0]), \"pred_forward_hrs\":6,\n",
    "         \"input_data_str_repr\":'folddirhb'}\n",
    "run_6 = {\"target_col\":'b_hs', \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir'], data=[0,0]), \"pred_forward_hrs\":4,\n",
    "         \"input_data_str_repr\":'folddirhb'}\n",
    "run_7 = {\"target_col\":'b_hs', \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs'], data=[0]), \"pred_forward_hrs\":6,\n",
    "         \"input_data_str_repr\":'hb'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T13:00:12.067105Z",
     "start_time": "2019-06-01T08:09:14.734514Z"
    }
   },
   "outputs": [],
   "source": [
    "all_results_new = []\n",
    "for i, all_args in enumerate([run_1, run_2, run_3, run_4, run_5, run_6, run_7]):\n",
    "    print(\"-----------------------\")\n",
    "    print(\"RUN NUMBER {}\".format(i+1))\n",
    "    print(\"-----------------------\")\n",
    "    all_results_new.append(multi_func_run(**all_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T18:07:31.557962Z",
     "start_time": "2019-06-01T18:07:31.539568Z"
    }
   },
   "outputs": [],
   "source": [
    "my_run = {\"target_col\":'b_hs', \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir', 'a_hs'], data=[0,0,0]), \"pred_forward_hrs\":6,\n",
    "         \"input_data_str_repr\":'hb'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T18:54:19.236133Z",
     "start_time": "2019-06-01T18:07:41.820627Z"
    }
   },
   "outputs": [],
   "source": [
    "multi_func_run(**my_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T08:08:24.617506Z",
     "start_time": "2019-06-01T08:06:52.065Z"
    }
   },
   "outputs": [],
   "source": [
    "all_results_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T07:55:03.981190Z",
     "start_time": "2019-06-01T07:55:03.953309Z"
    }
   },
   "outputs": [],
   "source": [
    "all_results_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T23:30:18.188300Z",
     "start_time": "2019-06-01T23:30:18.173054Z"
    }
   },
   "outputs": [],
   "source": [
    "target_col = \"a_hs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T09:10:18.474696Z",
     "start_time": "2019-06-09T09:10:18.409506Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Fold all run params (1-36)\n",
    "run_1 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs'], data=[0]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'hb', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_2 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs'], data=[0]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'hb', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_3 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs'], data=[0]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'hb', \"look_back_hrs\" : 6, \"time_sample_res_minutes\" : 10}\n",
    "run_4 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs'], data=[0]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'hb', \"look_back_hrs\" : 6, \"time_sample_res_minutes\" : 10}\n",
    "run_5 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs'], data=[0]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'hb', \"look_back_hrs\" : 24, \"time_sample_res_minutes\" : 30}\n",
    "run_6 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs'], data=[0]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'hb', \"look_back_hrs\" : 24, \"time_sample_res_minutes\" : 30}\n",
    "run_7 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs'], data=[0]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'hb', \"look_back_hrs\" : 48, \"time_sample_res_minutes\" : 60}\n",
    "run_8 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs'], data=[0]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'hb', \"look_back_hrs\" : 48, \"time_sample_res_minutes\" : 60}\n",
    "run_9 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir'], data=[0,0]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'folddirhb', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_10 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir'], data=[0,0]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'folddirhb', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_11 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir'], data=[0,0]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'folddirhb', \"look_back_hrs\" : 6, \"time_sample_res_minutes\" : 10}\n",
    "run_12 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir'], data=[0,0]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'folddirhb', \"look_back_hrs\" : 6, \"time_sample_res_minutes\" : 10}\n",
    "run_13 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir'], data=[0,0]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'folddirhb', \"look_back_hrs\" : 48, \"time_sample_res_minutes\" : 60}\n",
    "run_14 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir'], data=[0,0]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'folddirhb', \"look_back_hrs\" : 48, \"time_sample_res_minutes\" : 60}\n",
    "run_15 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir'], data=[0,2]), \"pred_forward_hrs\": 6,\n",
    "         \"input_data_str_repr\":'folddir2hb', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_16 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir'], data=[0,2]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'folddir2hb', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_17 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir'], data=[2,0]), \"pred_forward_hrs\": 6,\n",
    "         \"input_data_str_repr\":'folddirhb2', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_18 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir'], data=[2,0]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'folddirhb2', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_19 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir', 'ma_hs'], data=[0,0,4]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'folddirhbma4', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_20 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir', 'ma_hs'], data=[0,0, 4]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'folddirhbma4', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_190 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir', 'ma_hs'], data=[0,0,6]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'folddirhbma6', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_200 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['b_hs', 'b_dir', 'ma_hs'], data=[0,0, 6]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'folddirhbma6', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_21 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['ma_hs'], data=[2]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'ma2', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_22 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['ma_hs'], data=[2]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'ma2', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_23 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['ma_hs'], data=[4]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'ma4', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_24 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['ma_hs'], data=[4]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'ma4', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_25 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['ma_hs'], data=[6]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'ma6', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_26 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['ma_hs'], data=[6]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'ma6', \"look_back_hrs\" : 12, \"time_sample_res_minutes\" : 10}\n",
    "run_27 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['ma_hs'], data=[4]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'ma4', \"look_back_hrs\" : 6, \"time_sample_res_minutes\" : 10}\n",
    "run_28 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['ma_hs'], data=[4]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'ma4', \"look_back_hrs\" : 6, \"time_sample_res_minutes\" : 10}\n",
    "run_29 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['ma_hs'], data=[4]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'ma4', \"look_back_hrs\" : 24, \"time_sample_res_minutes\" : 30}\n",
    "run_30 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['ma_hs'], data=[4]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'ma4', \"look_back_hrs\" : 24, \"time_sample_res_minutes\" : 30}\n",
    "run_31 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['ma_hs'], data=[6]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'ma6', \"look_back_hrs\" : 24, \"time_sample_res_minutes\" : 30}\n",
    "run_32 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['ma_hs'], data=[6]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'ma6', \"look_back_hrs\" : 24, \"time_sample_res_minutes\" : 30}\n",
    "run_33 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['ma_hs'], data=[8]), \"pred_forward_hrs\": 4,\n",
    "         \"input_data_str_repr\":'ma8', \"look_back_hrs\" : 24, \"time_sample_res_minutes\" : 30}\n",
    "run_34 = {\"target_col\": target_col, \"col_names_and_offsets\": \\\n",
    "         pd.Series(index=['ma_hs'], data=[8]), \"pred_forward_hrs\": 2,\n",
    "         \"input_data_str_repr\":'ma8', \"look_back_hrs\" : 24, \"time_sample_res_minutes\" : 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T23:39:53.019596Z",
     "start_time": "2019-06-01T23:39:53.002763Z"
    }
   },
   "outputs": [],
   "source": [
    "runs = [run_1, run_2, run_2, run_4, run_5, run_6, run_7, run_8, run_9, run_10, run_11,\n",
    "       run_12, run_13, run_14, run_15, run_16, run_17, run_18, run_19, run_20, run_190, run_200, run_21,\n",
    "       run_22, run_23, run_24, run_25, run_26, run_27, run_28, run_29, run_30, run_31,\n",
    "       run_32, run_33, run_34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-01T23:39:58.972Z"
    }
   },
   "outputs": [],
   "source": [
    "all_results = []\n",
    "all_results_file_names = []\n",
    "for i, all_args in enumerate(runs):\n",
    "    print(\"-----------------------\")\n",
    "    print(\"RUN NUMBER {}\".format(i+1))\n",
    "    print(\"-----------------------\")\n",
    "    results, results_file_name = multi_func_run(**all_args)\n",
    "    all_results.append(results)\n",
    "    all_results_file_names.append(results_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T09:17:28.118313Z",
     "start_time": "2019-06-09T09:17:28.069891Z"
    }
   },
   "outputs": [],
   "source": [
    "all_args = run_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T11:56:30.084399Z",
     "start_time": "2019-06-09T09:17:32.622377Z"
    }
   },
   "outputs": [],
   "source": [
    "results, results_file_name = multi_func_run(**all_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T09:05:31.878564Z",
     "start_time": "2019-06-09T09:05:31.781566Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(all_results_file_names, open(\"temp_all_results_names.pkl\", \"wb\"))\n",
    "pickle.dump(all_results, open(\"temp_all_results.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T09:07:37.252414Z",
     "start_time": "2019-06-09T09:07:37.031101Z"
    }
   },
   "outputs": [],
   "source": [
    "for res, name in zip(all_results, all_results_file_names):\n",
    "    print(name)\n",
    "    display(res.groupby(level=1).mean()[['rmse', 'r2', 'si', 'mae', 'max_error']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T23:38:40.249407Z",
     "start_time": "2019-06-01T23:38:40.234057Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T09:06:18.721515Z",
     "start_time": "2019-06-09T09:06:18.542304Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "print(DESC_STR)\n",
    "results.groupby(level=1).mean()[['rmse', 'r2', 'si', 'mae', 'max_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Advanced.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "358.264px",
    "left": "1684px",
    "top": "620.167px",
    "width": "274.056px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
